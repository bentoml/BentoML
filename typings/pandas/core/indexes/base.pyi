from typing import TYPE_CHECKING, Any, Callable, Hashable, Literal, Sequence
import numpy as np
from pandas import DataFrame, RangeIndex, Series
from pandas._libs import index as libindex
from pandas._libs.tslibs import NaTType
from pandas._typing import AnyArrayLike, ArrayLike, Dtype, DtypeObj, Shape, final
from pandas.core.arrays import ExtensionArray
from pandas.core.base import IndexOpsMixin, PandasObject
from pandas.io.formats.printing import PrettyDict
from pandas.util._decorators import (
    Appender,
    cache_readonly,
    deprecate_nonkeyword_arguments,
    doc,
)

if TYPE_CHECKING: ...
__all__ = ["Index"]
_unsortable_types = ...
_index_doc_kwargs: dict[str, str] = ...
_index_shared_docs: dict[str, str] = ...
str_t = str
_o_dtype = ...

def disallow_kwargs(kwargs: dict[str, Any]) -> None: ...

_IndexT = ...

class Index(IndexOpsMixin, PandasObject):
    _hidden_attrs: frozenset[str] = ...
    _join_precedence = ...
    _typ: str = ...
    _data: ExtensionArray | np.ndarray
    _id: object | None = ...
    _name: Hashable = ...
    _no_setting_name: bool = ...
    _comparables: list[str] = ...
    _attributes: list[str] = ...
    _is_numeric_dtype: bool = ...
    _can_hold_na: bool = ...
    _can_hold_strings: bool = ...
    _engine_type: type[libindex.IndexEngine] = ...
    _supports_partial_string_indexing = ...
    _accessors = ...
    str = ...
    def __new__(
        cls, data=..., dtype=..., copy=..., name=..., tupleize_cols=..., **kwargs
    ) -> Index: ...
    @property
    def asi8(self): ...
    @final
    def is_(self, other) -> bool: ...
    def __len__(self) -> int: ...
    def __array__(self, dtype=...) -> np.ndarray: ...
    def __array_wrap__(self, result, context=...): ...
    @cache_readonly
    def dtype(self) -> DtypeObj: ...
    @final
    def ravel(self, order=...): ...
    def view(self, cls=...): ...
    def astype(self, dtype, copy=...): ...
    @Appender(_index_shared_docs["take"] % _index_doc_kwargs)
    def take(
        self, indices, axis: int = ..., allow_fill: bool = ..., fill_value=..., **kwargs
    ): ...
    @Appender(_index_shared_docs["repeat"] % _index_doc_kwargs)
    def repeat(self, repeats, axis=...): ...
    def copy(
        self: _IndexT,
        name: Hashable | None = ...,
        deep: bool = ...,
        dtype: Dtype | None = ...,
        names: Sequence[Hashable] | None = ...,
    ) -> _IndexT: ...
    @final
    def __copy__(self: _IndexT, **kwargs) -> _IndexT: ...
    @final
    def __deepcopy__(self: _IndexT, memo=...) -> _IndexT: ...
    @final
    def __repr__(self) -> str_t: ...
    def format(
        self, name: bool = ..., formatter: Callable | None = ..., na_rep: str_t = ...
    ) -> list[str_t]: ...
    @final
    def to_native_types(self, slicer=..., **kwargs) -> np.ndarray: ...
    def to_flat_index(self): ...
    def to_series(self, index=..., name: Hashable = ...) -> Series: ...
    def to_frame(self, index: bool = ..., name: Hashable = ...) -> DataFrame: ...
    @property
    def name(self): ...
    @name.setter
    def name(self, value: Hashable): ...
    names = ...
    @deprecate_nonkeyword_arguments(version=None, allowed_args=["self", "names"])
    def set_names(self, names, level=..., inplace: bool = ...): ...
    def rename(self, name, inplace=...): ...
    @property
    def nlevels(self) -> int: ...
    def sortlevel(self, level=..., ascending=..., sort_remaining=...): ...
    get_level_values = ...
    @final
    def droplevel(self, level=...): ...
    @final
    @property
    def is_monotonic(self) -> bool: ...
    @property
    def is_monotonic_increasing(self) -> bool: ...
    @property
    def is_monotonic_decreasing(self) -> bool: ...
    @cache_readonly
    def is_unique(self) -> bool: ...
    @final
    @property
    def has_duplicates(self) -> bool: ...
    @final
    def is_boolean(self) -> bool: ...
    @final
    def is_integer(self) -> bool: ...
    @final
    def is_floating(self) -> bool: ...
    @final
    def is_numeric(self) -> bool: ...
    @final
    def is_object(self) -> bool: ...
    @final
    def is_categorical(self) -> bool: ...
    @final
    def is_interval(self) -> bool: ...
    @final
    def is_mixed(self) -> bool: ...
    @final
    def holds_integer(self) -> bool: ...
    @cache_readonly
    def inferred_type(self) -> str_t: ...
    @cache_readonly
    @final
    def is_all_dates(self) -> bool: ...
    def __reduce__(self): ...
    _na_value: float | NaTType = ...
    @cache_readonly
    def hasnans(self) -> bool: ...
    @final
    def isna(self) -> np.ndarray: ...
    isnull = ...
    @final
    def notna(self) -> np.ndarray: ...
    notnull = ...
    def fillna(self, value=..., downcast=...): ...
    def dropna(self: _IndexT, how: str_t = ...) -> _IndexT: ...
    def unique(self: _IndexT, level: Hashable | None = ...) -> _IndexT: ...
    @deprecate_nonkeyword_arguments(version=None, allowed_args=["self"])
    def drop_duplicates(self: _IndexT, keep: str_t | bool = ...) -> _IndexT: ...
    def duplicated(self, keep: Literal["first", "last", False] = ...) -> np.ndarray: ...
    def __iadd__(self, other): ...
    @final
    def __and__(self, other): ...
    @final
    def __or__(self, other): ...
    @final
    def __xor__(self, other): ...
    @final
    def __nonzero__(self): ...
    __bool__ = ...
    @final
    def union(self, other, sort=...): ...
    @final
    def intersection(self, other, sort=...): ...
    @final
    def difference(self, other, sort=...): ...
    def symmetric_difference(self, other, result_name=..., sort=...): ...
    def get_loc(self, key, method=..., tolerance=...): ...
    @Appender(_index_shared_docs["get_indexer"] % _index_doc_kwargs)
    @final
    def get_indexer(
        self, target, method: str_t | None = ..., limit: int | None = ..., tolerance=...
    ) -> np.ndarray: ...
    def reindex(
        self, target, method=..., level=..., limit=..., tolerance=...
    ) -> tuple[Index, np.ndarray | None]: ...
    @_maybe_return_indexers
    def join(
        self,
        other,
        how: str_t = ...,
        level=...,
        return_indexers: bool = ...,
        sort: bool = ...,
    ): ...
    @property
    def values(self) -> ArrayLike: ...
    @cache_readonly
    @doc(IndexOpsMixin.array)
    def array(self) -> ExtensionArray: ...
    @doc(IndexOpsMixin._memory_usage)
    def memory_usage(self, deep: bool = ...) -> int: ...
    @final
    def where(self, cond, other=...) -> Index: ...
    def is_type_compatible(self, kind: str_t) -> bool: ...
    def __contains__(self, key: Any) -> bool: ...
    __hash__: None
    @final
    def __setitem__(self, key, value): ...
    def __getitem__(self, key): ...
    def append(self, other: Index | Sequence[Index]) -> Index: ...
    def putmask(self, mask, value) -> Index: ...
    def equals(self, other: Any) -> bool: ...
    @final
    def identical(self, other) -> bool: ...
    @final
    def asof(self, label): ...
    def asof_locs(self, where: Index, mask: np.ndarray) -> np.ndarray: ...
    @final
    def sort_values(
        self,
        return_indexer: bool = ...,
        ascending: bool = ...,
        na_position: str_t = ...,
        key: Callable | None = ...,
    ): ...
    @final
    def sort(self, *args, **kwargs): ...
    def shift(self, periods=..., freq=...): ...
    def argsort(self, *args, **kwargs) -> np.ndarray: ...
    @final
    def get_value(self, series: Series, key): ...
    @final
    def set_value(self, arr, key, value): ...
    @Appender(_index_shared_docs["get_indexer_non_unique"] % _index_doc_kwargs)
    def get_indexer_non_unique(self, target) -> tuple[np.ndarray, np.ndarray]: ...
    @final
    def get_indexer_for(self, target, **kwargs) -> np.ndarray: ...
    _requires_unique_msg = ...
    @final
    def groupby(self, values) -> PrettyDict[Hashable, np.ndarray]: ...
    def map(self, mapper, na_action=...): ...
    def isin(self, values, level=...) -> np.ndarray: ...
    def slice_indexer(
        self,
        start: Hashable | None = ...,
        end: Hashable | None = ...,
        step: int | None = ...,
        kind: str_t | None = ...,
    ) -> slice: ...
    def get_slice_bound(self, label, side: str_t, kind=...) -> int: ...
    def slice_locs(self, start=..., end=..., step=..., kind=...): ...
    def delete(self: _IndexT, loc) -> _IndexT: ...
    def insert(self, loc: int, item) -> Index: ...
    def drop(self, labels, errors: str_t = ...) -> Index: ...
    def __abs__(self): ...
    def __neg__(self): ...
    def __pos__(self): ...
    def __inv__(self): ...
    def any(self, *args, **kwargs): ...
    def all(self, *args, **kwargs): ...
    @final
    @property
    def shape(self) -> Shape: ...

def ensure_index_from_sequences(sequences, names=...): ...
def ensure_index(index_like: AnyArrayLike | Sequence, copy: bool = ...) -> Index: ...
def ensure_has_len(seq): ...
def trim_front(strings: list[str]) -> list[str]: ...
def default_index(n: int) -> RangeIndex: ...
def maybe_extract_name(name, obj, cls) -> Hashable: ...
def get_unanimous_names(*indexes: Index) -> tuple[Hashable, ...]: ...
def unpack_nested_dtype(other: _IndexT) -> _IndexT: ...
