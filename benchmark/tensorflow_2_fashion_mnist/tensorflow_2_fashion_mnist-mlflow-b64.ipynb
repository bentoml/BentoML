{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Basic classification: Classify images of clothing\n",
    "A tensorflow serving style service example using MLFlow\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=tensorflow&ea=tensorflow_2_fashion_mnist&dt=tensorflow_2_fashion_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# add venv PATH to shell command PATH\n",
    "import sys, os\n",
    "if sys.base_prefix not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = f\"{sys.base_prefix}/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import io\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(_train_images, train_labels), (_test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "train_images = _train_images / 255.0\n",
    "test_images = _test_images / 255.0\n",
    "\n",
    "# pick up a test image\n",
    "d_test_img = _test_images[0]\n",
    "print(class_names[test_labels[0]])\n",
    "\n",
    "plt.imshow(255.0 - d_test_img, cmap='gray')\n",
    "plt.imsave(\"test.png\", 255.0 - d_test_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnist(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FashionMnist, self).__init__()\n",
    "        self.cnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def image_bytes2tensor(inputs):\n",
    "        inputs = tf.map_fn(lambda i: tf.io.decode_png(i, channels=1), inputs, dtype=tf.uint8)\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        inputs = (255.0 - inputs) / 255.0\n",
    "        inputs = tf.reshape(inputs, [-1, 28, 28])\n",
    "        return inputs\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(None,), dtype=tf.string)])\n",
    "    def predict_image(self, inputs):\n",
    "        inputs = self.image_bytes2tensor(inputs)\n",
    "        return self(inputs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.cnn(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lhan11blCaW7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "20896/60000 [=========>....................] - ETA: 4s - loss: 0.6068 - accuracy: 0.7890"
     ]
    }
   ],
   "source": [
    "model = FashionMnist()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer fashion_mnist is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32) for input (None, 28, 28), but it was re-called on a Tensor with incompatible shape (3, 784).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ankle boot', 'Pullover', 'Trouser']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model(tf.constant(np.reshape(test_images[:3], (-1, 28 * 28))))\n",
    "klass = tf.argmax(predict, axis=1)\n",
    "[class_names[k] for k in klass]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "And the model predicts a label as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define & save MLFlow Pyfunc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mlflow_tmp/tf.pkl/assets\n"
     ]
    }
   ],
   "source": [
    "tmpdir = 'mlflow_tmp'\n",
    "tf_model_path = os.path.join(str(tmpdir), \"tf.pkl\")\n",
    "tf.saved_model.save(model, tf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting benchmark_mlflow_pyfunc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile benchmark_mlflow_pyfunc.py\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import six\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.pyfunc.model\n",
    "from mlflow.models import Model\n",
    "\n",
    "\n",
    "def _load_pyfunc(path):\n",
    "    tf_model = tf.saved_model.load(path)\n",
    "    class Model:\n",
    "        class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                       'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "        def predict(self, inputs):\n",
    "            _bytes = [base64.b64decode(i) for i in inputs['str'].to_numpy().tolist()]\n",
    "            inputs = tf.constant(_bytes, dtype=tf.string)\n",
    "            outputs = tf_model.predict_image(inputs)\n",
    "            output_classes = tf.math.argmax(outputs, axis=1)\n",
    "            return [self.class_names[i] for i in output_classes]\n",
    "    return Model()\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tmpdir = 'mlflow_tmp'\n",
    "    tf_model_path = os.path.join(str(tmpdir), \"tf.pkl\")\n",
    "    model_path = os.path.join(str(tmpdir), \"model\")\n",
    "\n",
    "    model_config = Model(run_id=\"test\")\n",
    "    mlflow.pyfunc.save_model(path=model_path,\n",
    "                             data_path=tf_model_path,\n",
    "                             loader_module=os.path.basename(__file__)[:-3],\n",
    "                             code_path=[__file__],\n",
    "                             mlflow_model=model_config)\n",
    "\n",
    "    reloaded_model = mlflow.pyfunc.load_pyfunc(model_path)\n",
    "    print(reloaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark_mlflow_pyfunc.py:50: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\n",
      "  reloaded_model = mlflow.pyfunc.load_pyfunc(model_path)\n",
      "2020-03-12 17:33:38.765326: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-03-12 17:33:38.788000: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2712000000 Hz\n",
      "2020-03-12 17:33:38.788289: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5579bd3561c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-12 17:33:38.788312: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-03-12 17:33:38.788417: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "<benchmark_mlflow_pyfunc._load_pyfunc.<locals>.Model object at 0x7fcb5c754a90>\n"
     ]
    }
   ],
   "source": [
    "!rm -r {tmpdir}/model\n",
    "!python benchmark_mlflow_pyfunc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bentoml-dev-py36/lib/python3.6/site-packages/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2020/03/12 17:33:40 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
      "2020/03/12 17:33:40 INFO mlflow.pyfunc.backend: === Running command 'gunicorn --timeout=60 -b 127.0.0.1:5000 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2020-03-12 17:33:40 +0800] [42524] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-03-12 17:33:40 +0800] [42524] [INFO] Listening at: http://127.0.0.1:5000 (42524)\n",
      "[2020-03-12 17:33:40 +0800] [42524] [INFO] Using worker: sync\n",
      "[2020-03-12 17:33:40 +0800] [42527] [INFO] Booting worker with pid: 42527\n",
      "/opt/anaconda3/envs/bentoml-dev-py36/lib/python3.6/site-packages/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2020-03-12 17:33:42.313731: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-03-12 17:33:42.339998: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2712000000 Hz\n",
      "2020-03-12 17:33:42.340276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e71f6a70c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-12 17:33:42.340323: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-03-12 17:33:42.340485: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "^C\n",
      "\n",
      "Aborted!\n",
      "[2020-03-12 17:33:42 +0800] [42524] [INFO] Handling signal: int\n"
     ]
    }
   ],
   "source": [
    "!mlflow models serve -m mlflow_tmp/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build & Run in Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace PIP_INDEX_URL with your prefer pypi mirror\n",
    "NAME = saved_path.split('/')[-1].lower()\n",
    "!docker build -t {NAME} \\\n",
    "    --build-arg PIP_TRUSTED_HOST=192.168.138.2 \\\n",
    "    --build-arg PIP_INDEX_URL=http://192.168.138.2/simple \\\n",
    "    {saved_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bentoml.utils import detect_free_port\n",
    "PORT = detect_free_port()\n",
    "print(PORT)\n",
    "\n",
    "!docker run -itd -p {PORT}:5000 --cpus 1 -e FLAGS=\"--workers 1 --enable-microbatch\" {NAME}:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"test.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()\n",
    "img_b64 = base64.b64encode(img_bytes).decode()\n",
    "\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "raw_data = np.array([img_b64])\n",
    "data = pd.DataFrame(raw_data, columns=['str']).to_json(orient='split')\n",
    "\n",
    "json_response = requests.post(f'http://127.0.0.1:5000/invocations', data=data, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark with locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing benchmark_mlflow_b64.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile benchmark_mlflow_b64.py\n",
    "from locust import HttpLocust, TaskSet, task, constant\n",
    "from functools import lru_cache\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def data_producer():\n",
    "\n",
    "    with open(\"test.png\", \"rb\") as f:\n",
    "        img_bytes = f.read()\n",
    "    img_b64 = base64.b64encode(img_bytes).decode()\n",
    "\n",
    "    def _gen_data(size=3):\n",
    "        headers = {\"content-type\": \"application/json\"}\n",
    "        raw_data = np.array([img_b64] * size)\n",
    "        data = pd.DataFrame(raw_data, columns=['str']).to_json(orient='split')\n",
    "        return headers, data\n",
    "\n",
    "    return _gen_data\n",
    "\n",
    "\n",
    "class WebsiteTasks(TaskSet):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data():\n",
    "        headers, data = data_producer()(1)\n",
    "        return headers, data\n",
    "        \n",
    "    @task\n",
    "    def index(self):\n",
    "        headers, data = self.get_data()\n",
    "        self.client.post(\"/invocations\", data, headers=headers)\n",
    "\n",
    "class WebsiteUser(HttpLocust):\n",
    "    task_set = WebsiteTasks\n",
    "    wait_time = constant(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-12 17:37:05,684] beta/INFO/locust.main: Starting web monitor at http://*:8089\n",
      "[2020-03-12 17:37:05,684] beta/INFO/locust.main: Starting Locust 0.14.4\n",
      "[2020-03-12 17:37:25,034] beta/WARNING/locust.runners: Your selected hatch rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\n",
      "[2020-03-12 17:37:25,036] beta/INFO/locust.runners: Hatching and swarming 1000 users at the rate 1000 users/s (0 users already running)...\n",
      "[2020-03-12 17:37:26,967] beta/INFO/locust.runners: All locusts hatched: WebsiteUser: 1000 (0 already running)\n",
      "[2020-03-12 17:40:07,358] beta/WARNING/locust.runners: Your selected hatch rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\n",
      "[2020-03-12 17:40:07,359] beta/INFO/locust.runners: Hatching and swarming 100 users at the rate 1000 users/s (0 users already running)...\n",
      "[2020-03-12 17:40:07,524] beta/INFO/locust.runners: All locusts hatched: WebsiteUser: 100 (0 already running)\n",
      "^C\n",
      "[2020-03-12 17:44:13,804] beta/ERROR/stderr: KeyboardInterrupt\n",
      "[2020-03-12 17:44:13,805] beta/ERROR/stderr: 2020-03-12T09:44:13Z\n",
      "[2020-03-12 17:44:13,805] beta/ERROR/stderr: \n",
      "[2020-03-12 17:44:13,805] beta/INFO/locust.main: Shutting down (exit code 0), bye.\n",
      "[2020-03-12 17:44:13,805] beta/INFO/locust.main: Cleaning up runner...\n",
      "[2020-03-12 17:44:13,806] beta/INFO/locust.main: Running teardowns...\n",
      " Name                                                          # reqs      # fails     Avg     Min     Max  |  Median   req/s failures/s\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      " POST /invocations                                              33772     0(0.00%)     209       5     691  |     190  140.84    0.00\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      " Aggregated                                                     33772     0(0.00%)     209       5     691  |     190  140.84    0.00\n",
      "\n",
      "Percentage of the requests completed within given times\n",
      " Type                 Name                                                           # reqs    50%    66%    75%    80%    90%    95%    98%    99%  99.9% 99.99%   100%\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " POST                 /invocations                                                    33772    190    250    270    290    360    410    500    560    650    670    690\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " None                 Aggregated                                                      33772    190    250    270    290    360    410    500    560    650    670    690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!locust -f benchmark_mlflow_b64.py -H http://127.0.0.1:{PORT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "bentoml-dev-py36",
   "language": "python",
   "name": "bentoml-dev-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
