{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a682ea0b",
   "metadata": {},
   "source": [
    "# BentoML TensorFlow2 MNIST Tutorial\n",
    "\n",
    "Link to source code: https://github.com/bentoml/BentoML/tree/main/examples/tensorflow2_keras/\n",
    "\n",
    "The code is based on the TensorFlow2 example code here: https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "\n",
    "Install required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad00863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84988464",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "If you are running MacOS use the following pip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements-macos.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45393b74",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "First let's initiate the dataset we'll be using and then create a Model which we will use to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeff07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import bentoml\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28, 1).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 28, 28, 1).astype(\"float32\") / 255\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation=\"relu\")\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation=\"relu\")\n",
    "        self.d2 = Dense(10)\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([None, 28, 28, 1], tf.float32)])\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7e68a-427b-4563-9b34-d8465c2db832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f8c40-b4b9-4824-b9cf-aea4959c27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38888f0a",
   "metadata": {},
   "source": [
    "## Training and Saving the model\n",
    "\n",
    "Then we initialize some simple tensorflow helper functions and create the training and testing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2104a6",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "As provided by TensorFlow, we train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85432d-4954-4321-bdcd-a65e292d9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae77afe-a3d7-45d3-a86c-d1bd59dde8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d9b23c",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "Finally, we make one call to the bentoml library to save this tensorflow model to be used later as part of the prediction service that we will create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bentoml.tensorflow.save_model(\n",
    "    \"tensorflow_mnist\",\n",
    "    model,\n",
    "    signatures={\"__call__\": {\"batchable\": True, \"batch_dim\": 0}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf35e55",
   "metadata": {},
   "source": [
    "## Create a BentoML Service for serving the model\n",
    "\n",
    "Note: using `%%writefile` here because `bentoml.Service` instance must be created in a separate `.py` file\n",
    "\n",
    "Even though we have only one model, we can create as many api endpoints as we want. Here we create two end points `predict_ndarray` and `predict_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile service.py\n",
    "\n",
    "import bentoml\n",
    "import numpy as np\n",
    "from bentoml.io import Image, NumpyNdarray\n",
    "from PIL.Image import Image as PILImage\n",
    "\n",
    "mnist_runner = bentoml.tensorflow.get(\"tensorflow_mnist:latest\").to_runner()\n",
    "\n",
    "svc = bentoml.Service(\n",
    "    name=\"tensorflow_mnist_demo\",\n",
    "    runners=[mnist_runner],\n",
    ")\n",
    "\n",
    "@svc.api(input=Image(), output=NumpyNdarray(dtype=\"float32\"))\n",
    "async def predict_image(f: PILImage) -> \"np.ndarray\":\n",
    "    assert isinstance(f, PILImage)\n",
    "    arr = np.array(f)/255.0\n",
    "    assert arr.shape == (28, 28)\n",
    "\n",
    "    # We are using greyscale image and our PyTorch model expect one\n",
    "    # extra channel dimension\n",
    "    arr = np.expand_dims(arr, (0, 3)).astype(\"float32\") # reshape to [1, 28, 28, 1]\n",
    "    return await mnist_runner.async_run(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590147aa",
   "metadata": {},
   "source": [
    "Start a dev model server to test out the service defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29173871",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve service.py:svc --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c1b36",
   "metadata": {},
   "source": [
    "Now you can use something like:\n",
    "\n",
    "`curl -H \"Content-Type: multipart/form-data\" -F'fileobj=@samples/0.png;type=image/png' http://127.0.0.1:3000/predict_image`\n",
    "    \n",
    "to send an image to the digit recognition service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372c692",
   "metadata": {},
   "source": [
    "We can also do a simple local benchmark if [locust](https://locust.io/) is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "!locust --headless -u 500 -r 10 --run-time 10m --host http://127.0.0.1:3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03564",
   "metadata": {},
   "source": [
    "## Build a Bento for distribution and deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f7406",
   "metadata": {},
   "source": [
    "A `bentofile` is already created in this directory for building a Bento for the service:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757297b",
   "metadata": {},
   "source": [
    "```yaml\n",
    "service: \"service:svc\"\n",
    "description: \"file: ./README.md\"\n",
    "labels:\n",
    "  owner: bentoml-team\n",
    "  stage: demo\n",
    "include:\n",
    "- \"*.py\"\n",
    "exclude:\n",
    "- \"tests/\"\n",
    "python:\n",
    "  lock_packages: False\n",
    "  packages:\n",
    "    - tensorflow\n",
    "    - Pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8e50a",
   "metadata": {},
   "source": [
    "Note that we exclude `tests/` from the bento using exclude.\n",
    "\n",
    "Simply run `bentoml build` from current directory to build a Bento with the latest version of the `tensorflow_mnist` model. This may take a while when running for the first time for BentoML to resolve all dependency versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36306933",
   "metadata": {},
   "source": [
    "Starting a dev server with the Bento build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve tensorflow2_demo:latest"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "tf2-py3.7",
   "language": "python",
   "name": "tf2-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "name": "tensorflow2_mnist_demo.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
