{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BentoML Example: Titanic Survival Prediction with XGBoost\n",
    "\n",
    "[BentoML](http://bentoml.ai) is an open source framework for building, shipping and running machine learning services. It provides high-level APIs for defining an ML service and packaging its artifacts, source code, dependencies, and configurations into a production-system-friendly format that is ready for deployment.\n",
    "\n",
    "This notebook demonstrates how to use BentoML to turn a XGBoost model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=nb&ea=open&el=official-example&dt=xgboost-tiantic-survival-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bentoml\n",
    "!pip install xgboost numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import bentoml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "download dataset from https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!curl https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv -o ./data/train.csv\n",
    "!curl https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/test.csv -o ./data/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test  = pd.read_csv(\"./data/test.csv\")\n",
    "X_y_train = xgb.DMatrix(data=train[['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']], label= train['Survived'])\n",
    "X_test    = xgb.DMatrix(data=test[['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Pclass', 'Age', 'Fare', 'SibSp', 'Parch', 'Survived']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'base_score': np.mean(train['Survived']),\n",
    "          'eta':  0.1,\n",
    "          'max_depth': 3,\n",
    "          'gamma' :3,\n",
    "          'objective'   :'reg:linear',\n",
    "          'eval_metric' :'mae'\n",
    "         }\n",
    "model = xgb.train(params=params, \n",
    "                  dtrain=X_y_train, \n",
    "                  num_boost_round=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=  model.predict(X_test)\n",
    "test['pred'] = y_test\n",
    "test[['Pclass', 'Age', 'Fare', 'SibSp', 'Parch','pred']].iloc[10:].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ML service with BentoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile xgboost_titanic_model.py\n",
    "import xgboost as xgb\n",
    "\n",
    "import bentoml\n",
    "from bentoml.artifact import XgboostModelArtifact\n",
    "from bentoml.handlers import DataframeHandler\n",
    "\n",
    "@bentoml.artifacts([XgboostModelArtifact('model')])\n",
    "@bentoml.env(pip_dependencies=['xgboost'])\n",
    "class TitanicModel(bentoml.BentoService):\n",
    "    \n",
    "    @bentoml.api(DataframeHandler)\n",
    "    def predict(self, df):\n",
    "        data = xgb.DMatrix(data=df[['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']])\n",
    "        return self.artifacts.model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save BentoML service archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost_titanic_model import TitanicModel\n",
    "\n",
    "bento_model = TitanicModel.pack(\n",
    "    model = model\n",
    ")\n",
    "\n",
    "# Save bento model to a directory\n",
    "saved_path = bento_model.save('/tmp/bento')\n",
    "\n",
    "print(saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from BentoML service archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "bento_model = bentoml.load(saved_path)\n",
    "\n",
    "result = bento_model.predict(test)\n",
    "test['pred'] = result\n",
    "test[['Pclass', 'Age', 'Fare', 'SibSp', 'Parch','pred']].iloc[10:].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run REST API server with Docker\n",
    "\n",
    "** _Note: `docker` is not available when running in Google Colaboratory_\n",
    "\n",
    "*For demo purpurse, copy generated model to ./model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "shutil.rmtree('./model', ignore_errors=True)\n",
    "shutil.copytree(saved_path, './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy following command to make a curl request to Rest API server\n",
    "\n",
    "```bash\n",
    "curl -i \\\n",
    "--header \"Content-Type: application/json\" \\\n",
    "--request POST \\\n",
    "--data '[{\"Pclass\": 1, \"Age\": 30, \"Fare\": 200, \"SibSp\": 1, \"Parch\": 0}]' \\\n",
    "localhost:5000/predict\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
