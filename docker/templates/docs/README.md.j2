{% macro sentence_case(text) %}
{{ text[0] | upper }}{{ text[1:] }}
{% endmacro %}
{% if metadata.ephemeral %}
{# This will be part of ./generated #}
## GENERATED DIRECTORY - DO NOT EDIT

The files are maintained by `manager.py`, which generates Dockerfile from `templates`.
Refers to [main README](../README.md) for more information.

{% else %}
## Model Serving Made Easy  [![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=BentoML:%20Machine%20Learning%20Model%20Serving%20Made%20Easy%20&url=https://github.com/bentoml/BentoML&via=bentomlai&hashtags=mlops,modelserving,ML,AI,machinelearning,bentoml)

[![pypi_status](https://img.shields.io/pypi/v/bentoml.svg)](https://pypi.org/project/BentoML)
[![downloads](https://pepy.tech/badge/bentoml)](https://pepy.tech/project/bentoml)
[![actions_status](https://github.com/bentoml/bentoml/workflows/BentoML-CI/badge.svg)](https://github.com/bentoml/bentoml/actions)
[![documentation_status](https://readthedocs.org/projects/bentoml/badge/?version=latest)](https://docs.bentoml.org/)
[![join_slack](https://badgen.net/badge/Join/BentoML%20Slack/cyan?icon=slack)](https://join.slack.com/t/bentoml/shared_invite/enQtNjcyMTY3MjE4NTgzLTU3ZDc1MWM5MzQxMWQxMzJiNTc1MTJmMzYzMTYwMjQ0OGEwNDFmZDkzYWQxNzgxYWNhNjAxZjk4MzI4OGY1Yjg)

BentoML let you create machine learning powered prediction service in minutes and bridges the gap between data science and DevOps.

ðŸ‘‰ Join our [slack community](https://join.slack.com/t/bentoml/shared_invite/enQtNjcyMTY3MjE4NTgzLTU3ZDc1MWM5MzQxMWQxMzJiNTc1MTJmMzYzMTYwMjQ0OGEwNDFmZDkzYWQxNzgxYWNhNjAxZjk4MzI4OGY1Yjg)


## Why BentoML

- The easiest way to get your ML models into production.
- High performance model serving, all in Python.
- Package your model once and deploy it anywhere.
- Support all major ML model training [frameworks](https://docs.bentoml.org/en/latest/frameworks.html).

## Getting Started

- [Quickstart guide](https://docs.bentoml.org/en/latest/quickstart.html) will show you a simple example of using BentoML in action. In under 10 minutes, you'll be able to serve your ML model over an HTTP API endpoint, and build a docker image that is ready to be deployed in production.
- [Main concepts](https://docs.bentoml.org/en/latest/concepts.html) will give a comprehensive tour of BentoML's components and introduce you to its philosophy. After reading, you will see what drives BentoML's design, and know what `bento` and `runner` stands for.
- Playground notebook gets your hands dirty in a notebook environment, for you to try out all the core features in BentoML.
- [ML Frameworks](https://docs.bentoml.org/en/latest/frameworks.html) lays out best practices and example usages by the ML framework used for training models.
- [Advanced Guides](https://docs.bentoml.org/en/latest/guides/index.html) show cases advanced features in BentoML, including GPU support, inference graph, monitoring, and customizing docker environment etc.


## BentoServer base images

There are three type of BentoServer docker base image:

| Image Type | Description                                | Supported OS                                          | Usage                             |
|------------|--------------------------------------------|-------------------------------------------------------|-----------------------------------|
| `runtime`  | contains latest BentoML releases from PyPI | `debian`, `centos{7,8}`, `amazonlinux2`, `alpine3.14` | production ready                  |
| `cudnn`    | runtime + support for CUDA-enabled GPU     | `debian`, `centos{7,8}`                               | production ready with GPU support |
| `devel`    | nightly build from development branch      | `debian`, `centos{7,8}`                               | for development use only          |

* Note: currently there's no nightly devel image with GPU support.

The final docker image tags will have the following format:

```markdown
<release_type>-<python_version>-<distros>-<suffix>
   â”‚             â”‚                â”‚        â”‚
   â”‚             â”‚                â”‚        â””â”€> additional suffix, differentiate runtime and cudnn releases
   â”‚             â”‚                â””â”€> formatted <dist><dist_version>, e.g: ami2, debian, centos7
   â”‚             â””â”€> Supported Python version: python3.7 | python3.8 | python3.9
   â””â”€>  Release type: devel or official BentoML release (e.g: 1.0.0)
```

Example image tags:
- `bento-server:devel-python3.7-debian`
- `bento-server:1.0.0-python3.8-centos8-cudnn`
- `bento-server:1.0.0-python3.7-ami2-runtime`


## Latest tags for `{{ metadata.bentoml_package }} {{ metadata.bentoml_release_version }}`

{% for distros, tags_path in metadata.release_info.items() %}
    {% print"\n### " %}{% print sentence_case(distros) %}{% print "\n" %}
    {% if 'centos' in distros.lower() %}
*WARNING*: POSSIBLE MISSING IMAGE TAGS

Centos upstream images often fail security scans, thus there might be some images missing. Please refers to [Issues section](https://github.com/bentoml/BentoML/issues) for security notices.

    {% endif %}
    {% for (tag, path) in tags_path %}
        {% if metadata.bentoml_package in tag %}
        {% set tagname = tag.split(':')[1] %}
        {% print "- [`" %}{% print tagname %}{% print "`](https://github.com/bentoml/BentoML/tree/main/docker/" %}{% print path %}{% print ")\n" %}
        {% endif %}
    {% endfor %}
{% endfor %}
{% endif %}
{# We might want to include previous images here as well #}
