class ONNXQuantizer:
    def __init__(
        self,
        model,
        per_channel,
        reduce_range,
        mode,
        static,
        weight_qType,
        input_qType,
        tensors_range,
        nodes_to_quantize,
        nodes_to_exclude,
        op_types_to_quantize,
        extra_options=...,
    ) -> None: ...
    def quantize_subgraph(self, subgraph, graph_key): ...
    def quantize_node_with_sub_graph(self, node): ...
    def check_opset_version(self): ...
    def remove_fake_quantized_nodes(self): ...
    def find_initializer_in_path(self, initializer_name): ...
    def should_quantize(self, node): ...
    def add_new_nodes(self, nodes): ...
    def quantize_model(self): ...
    @staticmethod
    def tensor_proto_to_array(initializer): ...
    def is_input_a_weight(self, input_name): ...
    def is_per_channel(self): ...
    def is_valid_quantize_weight(self, weight_name): ...
    def quantize_bias_static(self, bias_name, input_name, weight_name): ...
    def contains_tensor(self, tensor_name): ...
    def quantize_inputs(
        self,
        node,
        indices,
        initializer_use_weight_qType=...,
        reduce_range=...,
        op_level_per_channel=...,
        axis=...,
        from_subgraph=...,
    ): ...
    def quantize_weight(self, weight, qType, reduce_range=...): ...
    def quantize_weight_per_channel(
        self, weight_name, weight_qType, channel_axis, reduce_range=...
    ): ...
    def calculate_quantization_params(self): ...
