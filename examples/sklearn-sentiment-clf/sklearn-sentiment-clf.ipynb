{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local bentoml repository\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "import bentoml\n",
    "\n",
    "print(bentoml.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment_analysis_twitter_model\n",
    "\n",
    "Based on https://github.com/crawles/sentiment_analysis_twitter_model/blob/master/build-sentiment-classifier.ipynb\n",
    "\n",
    "Using dataset from http://help.sentiment140.com/for-students/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget -q http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
    "unzip -n trainingandtestdata.zip\n",
    "rm trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['polarity', 'tweetid', 'date', 'query_name', 'user', 'text']\n",
    "dftrain = pd.read_csv('training.1600000.processed.noemoticon.csv',\n",
    "                      header = None,\n",
    "                      encoding ='ISO-8859-1')\n",
    "dftest = pd.read_csv('testdata.manual.2009.06.14.csv',\n",
    "                     header = None,\n",
    "                     encoding ='ISO-8859-1')\n",
    "dftrain.columns = columns\n",
    "dftest.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegexPreprocess(object):\n",
    "    \"\"\"Create a preprocessing module for a tweet or data structure of tweets.\n",
    "    1) replace username, e.g., @crawles -> USERNAME\n",
    "    2) replace http links -> URL\n",
    "    3) replace repeated letters to two letters\n",
    "    \"\"\"\n",
    "    \n",
    "    user_pat = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)'\n",
    "    http_pat = '(https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,})'\n",
    "    repeat_pat, repeat_repl = \"(.)\\\\1\\\\1+\",'\\\\1\\\\1'\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        is_pd_series = isinstance(X, pd.core.frame.Series)\n",
    "        if not is_pd_series:\n",
    "            pp_text = pd.Series(X)\n",
    "        else:\n",
    "            pp_text = X\n",
    "        pp_text = pp_text.str.replace(pat = self.user_pat, repl = 'USERNAME')\n",
    "        pp_text = pp_text.str.replace(pat = self.http_pat, repl = 'URL')\n",
    "        pp_text.str.replace(pat = self.repeat_pat, repl = self.repeat_repl)\n",
    "        return pp_text\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiment_lr = Pipeline([('regex_preprocess', RegexPreprocess()),\n",
    "                         ('count_vect', CountVectorizer(min_df = 100,\n",
    "                                                        ngram_range = (1,1),\n",
    "                                                        stop_words = 'english')), \n",
    "                         ('lr', LogisticRegression())])\n",
    "sentiment_lr.fit(dftrain.text, dftrain.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtest, ytest = dftest.text[dftest.polarity!=2], dftest.polarity[dftest.polarity!=2]\n",
    "print(classification_report(ytest,sentiment_lr.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lr.predict([\"stupid\", \"awesome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile sentiment_lr_model.py\n",
    "import pandas as pd\n",
    "import bentoml\n",
    "from bentoml.artifact import PickleArtifact\n",
    "from bentoml.handlers import DataframeHandler\n",
    "\n",
    "@bentoml.artifacts([PickleArtifact('sentiment_lr')])\n",
    "@bentoml.env(conda_dependencies=[\"scikit-learn\", \"pandas\"])\n",
    "class SentimentLRModel(bentoml.BentoService):\n",
    "\n",
    "    @bentoml.api(DataframeHandler)\n",
    "    def predict(self, df):\n",
    "        \"\"\"\n",
    "        predict expects dataframe as input\n",
    "        \"\"\"        \n",
    "        return self.artifacts.sentiment_lr.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_lr_model import SentimentLRModel\n",
    "\n",
    "# Initialize bentoML model with artifacts\n",
    "\n",
    "bento_model = SentimentLRModel.pack(\n",
    "    sentiment_lr=sentiment_lr\n",
    ")\n",
    "\n",
    "# Save bentoML model to directory\n",
    "saved_path = bento_model.save(\"/tmp/bento\")\n",
    "\n",
    "# print the directory containing exported model archive (prefixed with model name and version)\n",
    "print(saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "# Load exported bentoML model archive from path\n",
    "bento_model = bentoml.load(saved_path)\n",
    "\n",
    "# Call predict on the restored sklearn model\n",
    "bento_model.predict([\"hello\", \"hi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### * For demo purpurse, copy generated model to ./model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "shutil.rmtree('./model', ignore_errors=True)\n",
    "shutil.copytree(saved_path, './model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install exported model as a python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your bentoML model class name will become packaged name\n",
    "from SentimentLRModel import SentimentLRModel\n",
    "\n",
    "ms = SentimentLRModel.load() # call load to ensure all artifacts are loaded\n",
    "ms.predict([\"stupid\", \"awesome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build API server docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd \"./model\" && docker build -t atalaya/sentiment-lr-model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve --model-path=./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
