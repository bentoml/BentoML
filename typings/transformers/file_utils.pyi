import os
from collections import OrderedDict
from enum import Enum
from pathlib import Path
from tempfile import _TemporaryFileWrapper
from types import ModuleType
from typing import Any, BinaryIO, Callable, Dict, List, Optional, Tuple, Union, overload

CONFIG_NAME: str = ...
FLAX_WEIGHTS_NAME: str = ...
TF2_WEIGHTS_NAME: str = ...
WEIGHTS_NAME: str = ...

def requires_backends(obj, backends): ...
def add_start_docstrings(*docstr): ...
def add_start_docstrings_to_model_forward(*docstr): ...
def add_end_docstrings(*docstr: str) -> Callable[[Callable[..., Any]], Any]: ...
def add_code_sample_docstrings(
    *docstr,
    tokenizer_class=...,
    checkpoint=...,
    output_type=...,
    config_class=...,
    mask=...,
    model_cls=...
): ...
def replace_return_docstrings(output_type=..., config_class=...): ...
def is_remote_url(url_or_filename): ...
def hf_bucket_url(
    model_id: str,
    filename: str,
    subfolder: Optional[str] = ...,
    revision: Optional[str] = ...,
    mirror=...,
) -> str: ...
def url_to_filename(url: str, etag: Optional[str] = ...) -> str: ...
def filename_to_url(filename, cache_dir=...): ...
def get_cached_models(cache_dir: Union[str, Path] = ...) -> List[Tuple]: ...
def cached_path(
    url_or_filename,
    cache_dir=...,
    force_download=...,
    proxies=...,
    resume_download=...,
    user_agent: Union[Dict, str, None] = ...,
    extract_compressed_file=...,
    force_extract=...,
    use_auth_token: Union[bool, str, None] = ...,
    local_files_only=...,
) -> Optional[str]: ...
def define_sagemaker_information(): ...
def http_user_agent(user_agent: Union[Dict[str, Any], str, None] = ...) -> str: ...
@overload
def http_get(
    url: str,
    temp_file: _TemporaryFileWrapper[str],
    proxies: Optional[str] = ...,
    resume_size: int = ...,
    headers: Optional[Dict[str, str]] = ...,
) -> None: ...
@overload
def http_get(
    url: str,
    temp_file: BinaryIO,
    proxies: Optional[str] = ...,
    resume_size: int = ...,
    headers: Optional[Dict[str, str]] = ...,
) -> None: ...
def get_from_cache(
    url: str,
    cache_dir=...,
    force_download=...,
    proxies=...,
    etag_timeout=...,
    resume_download=...,
    user_agent: Union[Dict, str, None] = ...,
    use_auth_token: Union[bool, str, None] = ...,
    local_files_only=...,
) -> Optional[str]: ...
def get_list_of_files(
    path_or_repo: Union[str, os.PathLike],
    revision: Optional[str] = ...,
    use_auth_token: Optional[Union[bool, str]] = ...,
) -> List[str]: ...

class cached_property(property):
    def __get__(self, obj, objtype=...): ...

def torch_required(func): ...
def tf_required(func): ...
def is_torch_fx_proxy(x): ...
def is_tensor(x): ...
def to_py_obj(obj): ...

class ModelOutput(OrderedDict):
    def __post_init__(self): ...
    def __delitem__(self, *args, **kwargs): ...
    def setdefault(self, *args, **kwargs): ...
    def pop(self, *args, **kwargs): ...
    def update(self, *args, **kwargs): ...
    def __getitem__(self, k): ...
    def __setattr__(self, name, value): ...
    def __setitem__(self, key, value): ...
    def to_tuple(self) -> Tuple[Any]: ...

class ExplicitEnum(Enum): ...

class PaddingStrategy(ExplicitEnum):
    LONGEST = ...
    MAX_LENGTH = ...
    DO_NOT_PAD = ...

class TensorType(ExplicitEnum):
    PYTORCH = ...
    TENSORFLOW = ...
    NUMPY = ...
    JAX = ...

class _LazyModule(ModuleType):
    def __init__(
        self, name, module_file, import_structure, extra_objects=...
    ) -> None: ...
    def __dir__(self): ...
    def __getattr__(self, name: str) -> Any: ...
    def __reduce__(self): ...

def copy_func(f): ...
def is_local_clone(repo_path, repo_url): ...

class PushToHubMixin:
    def push_to_hub(
        self,
        repo_path_or_name: Optional[str] = ...,
        repo_url: Optional[str] = ...,
        use_temp_dir: bool = ...,
        commit_message: Optional[str] = ...,
        organization: Optional[str] = ...,
        private: Optional[bool] = ...,
        use_auth_token: Optional[Union[bool, str]] = ...,
    ) -> str: ...
