{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BentoML Example:  Text Classification with Keras\n",
    "\n",
    "[BentoML](http://bentoml.ai) is an open source framework for building, shipping and running machine learning services. It provides high-level APIs for defining an ML service and packaging its artifacts, source code, dependencies, and configurations into a production-system-friendly format that is ready for deployment.\n",
    "\n",
    "This notebook demonstrates how to use BentoML to turn a Keras model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
    "\n",
    "This notebook is built based on Keras's IMDB LSTM tutorial [here](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py).\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=nb&ea=open&el=official-example&dt=tf-keras-text-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -I bentoml\n",
    "!pip install tensorflow==1.13.1\n",
    "!pip install numpy==1.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorflow Version: %s\" % tf.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "import bentoml\n",
    "print(\"BentoML Version: %s\" % bentoml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "maxlen = 80 # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 300\n",
    "index_from=3 # word index offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAsKG535pHep"
   },
   "source": [
    "# Prepare Dataset\n",
    "Download the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary mapping words to an integer index\n",
    "imdb.load_data(num_words=max_features)\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+index_from) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "\n",
    "# Use decode_review to look at original review text in training/testing data\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_review(encoded_text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in encoded_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features, index_from=index_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train,\n",
    "                                 value=word_index[\"<PAD>\"],\n",
    "                                 padding='post',\n",
    "                                 maxlen=maxlen)\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test,\n",
    "                                value=word_index[\"<PAD>\"],\n",
    "                                padding='post',\n",
    "                                maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLC02j2g-llC"
   },
   "source": [
    "# Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpKOoWgu-llD"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXSGrjWZ-llW"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1, # for demo purpose :P\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOMKywn4zReN"
   },
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ML service with BentoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile text_classification_service.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from bentoml import api, env, BentoService, artifacts\n",
    "from bentoml.artifact import TfKerasModelArtifact, PickleArtifact\n",
    "from bentoml.handlers import JsonHandler\n",
    "\n",
    "max_features = 1000\n",
    "\n",
    "@artifacts([\n",
    "    TfKerasModelArtifact('model'),\n",
    "    PickleArtifact('word_index')\n",
    "])\n",
    "@env(conda_dependencies=['tensorflow', 'numpy', 'pandas'])\n",
    "class TextClassificationService(BentoService):\n",
    "   \n",
    "    def word_to_index(self, word):\n",
    "        if word in self.artifacts.word_index and self.artifacts.word_index[word] <= max_features:\n",
    "            return self.artifacts.word_index[word]\n",
    "        else:\n",
    "            return self.artifacts.word_index[\"<UNK>\"]\n",
    "    \n",
    "    def preprocessing(self, text_str):\n",
    "        sequence = text.text_to_word_sequence(text_str)\n",
    "        return list(map(self.word_to_index, sequence))\n",
    "    \n",
    "    @api(JsonHandler)\n",
    "    def predict(self, parsed_json):\n",
    "        if type(parsed_json) == list:\n",
    "            input_data = list(map(self.preprocessing, parsed_json))\n",
    "        else: # expecting type(parsed_json) == dict:\n",
    "            input_data = [self.preprocessing(parsed_json['text'])]\n",
    "\n",
    "        input_data = sequence.pad_sequences(input_data,\n",
    "                                            value=self.artifacts.word_index[\"<PAD>\"],\n",
    "                                            padding='post',\n",
    "                                            maxlen=80)\n",
    "\n",
    "        return self.artifacts.model.predict_classes(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save BentoML service archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from text_classification_service import TextClassificationService\n",
    "\n",
    "svc = TextClassificationService.pack(model=model, word_index=word_index)\n",
    "print(svc.predict({ 'text': 'bad worst terrible' }))\n",
    "saved_path = svc.save('/tmp/bento')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test packed BentoML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc.predict({ 'text': 'bad worst terrible' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc.predict(['the best movie I have ever seen', 'This is a bad movie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BentoML Service from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "bento_svc = bentoml.load(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bento_svc.predict({ \"text\": \"the best movie I have ever seen\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bento_svc.predict(['the best movie I have ever seen', 'This is a bad movie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run REST API server locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saved BentoML service archive can be loaded as a REST API server with bentoml cli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve {saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send prediction request to REST API server\n",
    "\n",
    "*Run the following command in terminal to make a HTTP request to the API server*\n",
    "```bash\n",
    "curl -i \\\n",
    "--header \"Content-Type: application/json\" \\\n",
    "--request POST \\\n",
    "--data '{\"text\": \"best movie ever\"}' \\\n",
    "localhost:5000/predict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"pip install\" a BentoML archive\n",
    "\n",
    "BentoML user can directly pip install saved BentoML archive with `pip install $SAVED_PATH`,  and use it as a regular python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install {saved_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TextClassificationService\n",
    "\n",
    "installed_svc = TextClassificationService.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installed_svc.predict({ 'text': 'the best movie I have ever seen' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installed_svc.predict({ 'text': 'This is a bad movie' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI access\n",
    "\n",
    "`pip install $SAVED_PATH` also installs a CLI tool for accessing the BentoML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!TextClassificationService --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print model service information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!TextClassificationService info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 'predict' api with json data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!TextClassificationService predict --input='{\"text\": \"bad movie\"}'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "basic-text-classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
