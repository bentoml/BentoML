"""
This type stub file was generated by pyright.
"""

import contextlib

from .parallel import AutoBatchingMixin, ParallelBackendBase

if distributed is not None:
    ...
def is_weakrefable(obj): # -> bool:
    ...

class _WeakKeyDictionary:
    """A variant of weakref.WeakKeyDictionary for unhashable objects.

    This datastructure is used to store futures for broadcasted data objects
    such as large numpy arrays or pandas dataframes that are not hashable and
    therefore cannot be used as keys of traditional python dicts.

    Furthermore using a dict with id(array) as key is not safe because the
    Python is likely to reuse id of recently collected arrays.
    """
    def __init__(self) -> None:
        ...
    
    def __getitem__(self, obj):
        ...
    
    def __setitem__(self, obj, value): # -> None:
        ...
    
    def __len__(self): # -> int:
        ...
    
    def clear(self): # -> None:
        ...
    


class Batch:
    """dask-compatible wrapper that executes a batch of tasks"""
    def __init__(self, tasks) -> None:
        ...
    
    def __call__(self, tasks=...): # -> list[Unknown]:
        ...
    
    def __repr__(self): # -> str:
        ...
    


class DaskDistributedBackend(AutoBatchingMixin, ParallelBackendBase):
    MIN_IDEAL_BATCH_DURATION = ...
    MAX_IDEAL_BATCH_DURATION = ...
    supports_timeout = ...
    def __init__(self, scheduler_host=..., scatter=..., client=..., loop=..., wait_for_workers_timeout=..., **submit_kwargs) -> None:
        ...
    
    def __reduce__(self): # -> tuple[Type[DaskDistributedBackend], tuple[()]]:
        ...
    
    def get_nested_backend(self): # -> tuple[DaskDistributedBackend, Literal[-1]]:
        ...
    
    def configure(self, n_jobs=..., parallel=..., **backend_args): # -> int:
        ...
    
    def start_call(self): # -> None:
        ...
    
    def stop_call(self): # -> None:
        ...
    
    def effective_n_jobs(self, n_jobs): # -> int:
        ...
    
    def apply_async(self, func, callback=...): # -> Future[Unknown]:
        ...
    
    def abort_everything(self, ensure_ready=...): # -> None:
        """ Tell the client to cancel any task submitted via this instance

        joblib.Parallel will never access those results
        """
        ...
    
    @contextlib.contextmanager
    def retrieval_context(self): # -> Generator[None, None, None]:
        """Override ParallelBackendBase.retrieval_context to avoid deadlocks.

        This removes thread from the worker's thread pool (using 'secede').
        Seceding avoids deadlock in nested parallelism settings.
        """
        ...
    


