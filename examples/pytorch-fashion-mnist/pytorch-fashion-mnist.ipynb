{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local bentoml repository\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "import bentoml\n",
    "\n",
    "print(bentoml.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoder\n",
    "\n",
    "source: https://github.com/baldassarreFe/zalando-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Load a custom subclass of torchvision.datasets.MNIST that instead downloads the FashionMNIST dataset \n",
    "\n",
    "(waiting for [this commit](https://github.com/pytorch/vision/commit/eec5ba4405c8815bd1797619d9cc9276f81b76f4) be available in the pip version of PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "class FashionMNIST(MNIST):\n",
    "    \"\"\"`Fashion MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "\n",
    "    input_shape = (28, 28)\n",
    "    num_classes = 10\n",
    "\n",
    "    labels = [\n",
    "        'T-shirt/top',\n",
    "        'Trouser',\n",
    "        'Pullover',\n",
    "        'Dress',\n",
    "        'Coat',\n",
    "        'Sandal',\n",
    "        'Shirt',\n",
    "        'Sneaker',\n",
    "        'Bag',\n",
    "        'Ankle boot'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir, 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test set in batches of 1000.\n",
    "\n",
    "The `28x28` images are scaled up to `29x29` so that combining convolutions and transposed convolutions would not chop off pixels from the reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "train_dataset = FashionMNIST(\n",
    "    './data', train=True, download=True, \n",
    "    transform=transforms.Compose([transforms.CenterCrop((29, 29)), transforms.ToTensor()]))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = FashionMNIST(\n",
    "    './data', train=False, download=True, \n",
    "    transform=transforms.Compose([transforms.CenterCrop((29, 29)), transforms.ToTensor()]))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(20, 40, kernel_size=5, stride=2)\n",
    "        self.fully = nn.Linear(40, embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1x29x29\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # 10x13x13\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # 20x5x5\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # 40x1x1\n",
    "        x = x.view(x.data.shape[0], 40)\n",
    "        # 40\n",
    "        x = self.fully(x)\n",
    "        # output_size\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fully = nn.Linear(input_size, 40)\n",
    "        self.conv1 = nn.ConvTranspose2d(40, 20, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.ConvTranspose2d(20, 10, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.ConvTranspose2d(10, 1, kernel_size=5, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fully(x)\n",
    "        x = x.view(x.data.shape[0], 40, 1, 1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.sigmoid(self.conv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 20\n",
    "encoder = Encoder(embedding_size)\n",
    "decoder = Decoder(embedding_size)\n",
    "\n",
    "autoencoder = nn.Sequential(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    encoder, \n",
    "    nn.Linear(embedding_size, 15),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(15, len(FashionMNIST.labels)),\n",
    "    nn.LogSoftmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train()\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam([p for p in classifier.parameters() if p.requires_grad])\n",
    "epoch_loss = []\n",
    "\n",
    "for epoch in range(2):\n",
    "    batch_loss = []\n",
    "    for batch_num, (data, targets) in enumerate(train_loader):\n",
    "        data, targets = Variable(data), Variable(targets)\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(data)\n",
    "        loss = loss_fn(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.data.item() )\n",
    "    epoch_loss.append(sum(batch_loss) / len(batch_loss))\n",
    "    accuracy = accuracy_score(targets.data.numpy(), output.data.numpy().argmax(axis=1))\n",
    "    print('Epoch {}:\\tloss {:.4f}\\taccuracy {:.2%}'.format(epoch, epoch_loss[-1], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "data, targets = next(test_loader.__iter__())\n",
    "outputs = classifier(Variable(data))\n",
    "log_probs, output_classes = outputs.max(dim=1)\n",
    "\n",
    "accuracy = accuracy_score(targets.numpy(), output_classes.data.numpy())\n",
    "print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axex = plt.subplots(8, 8, figsize=(16, 16))\n",
    "\n",
    "zip_these = axex.ravel(), log_probs.data.exp(), output_classes.data, targets, data.numpy().squeeze()\n",
    "for ax, prob, output_class, target, img in zip(*zip_these):\n",
    "    ax.imshow(img, cmap='gray' if output_class == target else 'autumn')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('{} {:.1%}'.format(FashionMNIST.labels[output_class], prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pytorch_fashion_mnist.py\n",
    "\n",
    "import bentoml\n",
    "from bentoml.artifact import PytorchModelArtifact\n",
    "from bentoml.handlers import PytorchTensorHandler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "@bentoml.env(conda_dependencies=['torch', 'numpy', 'torchvision', 'scikit-learn'])\n",
    "@bentoml.artifacts([PytorchModelArtifact('classifier')])\n",
    "class FashionMNISTModel(bentoml.BentoService):\n",
    "    \"\"\"\n",
    "    documentation strip\n",
    "    \"\"\"\n",
    "\n",
    "    @bentoml.api(PytorchTensorHandler)\n",
    "    def predict(self, tensor):\n",
    "        output_tensor = self.artifacts.classifier(Variable(tensor))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_fashion_mnist import FashionMNISTModel\n",
    "new_model = FashionMNISTModel.pack(classifier=classifier)\n",
    "\n",
    "\n",
    "saved_path = new_model.save('/tmp/bento')\n",
    "print(saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "saved_model = bentoml.load(saved_path)\n",
    "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=5, shuffle=True)\n",
    "testing_data, targets = next(data_loader.__iter__())\n",
    "\n",
    "#call prediction\n",
    "saved_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### * For demo purpurse, copy generated model to ./model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "shutil.rmtree('./model', ignore_errors=True)\n",
    "shutil.copytree(saved_path, './model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install exported model as a python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your bentoML model class name will become packaged name\n",
    "from FashionMNISTModel import FashionMNISTModel\n",
    "\n",
    "ms = FashionMNISTModel()\n",
    "result = ms.predict(testing_data)\n",
    "log_probs, output_classes = result.max(dim=1)\n",
    "\n",
    "accuracy = accuracy_score(targets.numpy(), output_classes.data.numpy())\n",
    "print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build API server docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd saved_path && docker build -t atalaya/sentiment-lr-model ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
