{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# add venv PATH to shell command PATH\n",
    "import sys, os\n",
    "if sys.base_prefix not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = f\"{sys.base_prefix}/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "NAME = 'linear_sleep'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & train model(not used, just placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  [2.   1.   0.   1.   1.59 0.   1.23 1.   0.   1.   2.   1.   0.   2.\n",
      " 0.   1.88 2.   2.   0.   0.   1.   2.   1.   1.38 1.52 1.88 1.   1.\n",
      " 2.   2.  ]\n",
      "  mse: 0.087487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, 2:]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)\n",
    "\n",
    "    \n",
    "# add parameters for tuning\n",
    "num_estimators = 100\n",
    "\n",
    "# train the model\n",
    "model = RandomForestRegressor(n_estimators=num_estimators)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print('predictions: ', predictions)\n",
    "\n",
    "# log model performance \n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"  mse: %f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting linear_sleep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {NAME}.py\n",
    "\n",
    "import bentoml\n",
    "import time\n",
    "from bentoml.artifact import SklearnModelArtifact\n",
    "from bentoml.handlers import DataframeHandler\n",
    "\n",
    "\n",
    "@bentoml.env()\n",
    "@bentoml.artifacts([SklearnModelArtifact('model')])\n",
    "class BentoSvc(bentoml.BentoService):\n",
    "    @bentoml.api(DataframeHandler)\n",
    "    def predict(self, inputs):\n",
    "        a, b = inputs.to_numpy()[0]\n",
    "        x = inputs.shape[0]\n",
    "        time.sleep(a * x + b)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-24 22:29:39,623] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.5.2. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-03-24 22:29:39,878] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.5.2. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-03-24 22:29:48,953] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.5.2. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "running sdist\n",
      "running egg_info\n",
      "writing BentoML.egg-info/PKG-INFO\n",
      "writing dependency_links to BentoML.egg-info/dependency_links.txt\n",
      "writing entry points to BentoML.egg-info/entry_points.txt\n",
      "writing requirements to BentoML.egg-info/requires.txt\n",
      "writing top-level names to BentoML.egg-info/top_level.txt\n",
      "reading manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "warning: no files found matching '*' under directory 'bentoml/yatai/web/dist'\n",
      "no previously-included directories found matching 'e2e_tests'\n",
      "no previously-included directories found matching 'tests'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating BentoML-0.5.2+144.g2865d83\n",
      "creating BentoML-0.5.2+144.g2865d83/BentoML.egg-info\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/bundler\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/clipper\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/configuration\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/configuration/__pycache__\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/deployment\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/deployment/aws_lambda\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/deployment/sagemaker\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/marshal\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/migrations\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/migrations/__pycache__\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/migrations/versions\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/migrations/versions/__pycache__\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/proto\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/repository\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/server/static\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/utils/validator\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/yatai\n",
      "creating BentoML-0.5.2+144.g2865d83/bentoml/yatai/client\n",
      "copying files to BentoML-0.5.2+144.g2865d83...\n",
      "copying LICENSE -> BentoML-0.5.2+144.g2865d83\n",
      "copying MANIFEST.in -> BentoML-0.5.2+144.g2865d83\n",
      "copying README.md -> BentoML-0.5.2+144.g2865d83\n",
      "copying pyproject.toml -> BentoML-0.5.2+144.g2865d83\n",
      "copying setup.cfg -> BentoML-0.5.2+144.g2865d83\n",
      "copying setup.py -> BentoML-0.5.2+144.g2865d83\n",
      "copying versioneer.py -> BentoML-0.5.2+144.g2865d83\n",
      "copying BentoML.egg-info/PKG-INFO -> BentoML-0.5.2+144.g2865d83/BentoML.egg-info\n",
      "copying BentoML.egg-info/SOURCES.txt -> BentoML-0.5.2+144.g2865d83/BentoML.egg-info\n",
      "copying BentoML.egg-info/dependency_links.txt -> BentoML-0.5.2+144.g2865d83/BentoML.egg-info\n",
      "copying BentoML.egg-info/entry_points.txt -> BentoML-0.5.2+144.g2865d83/BentoML.egg-info\n",
      "copying BentoML.egg-info/requires.txt -> BentoML-0.5.2+144.g2865d83/BentoML.egg-info\n",
      "copying BentoML.egg-info/top_level.txt -> BentoML-0.5.2+144.g2865d83/BentoML.egg-info\n",
      "copying bentoml/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml\n",
      "copying bentoml/_version.py -> BentoML-0.5.2+144.g2865d83/bentoml\n",
      "copying bentoml/alembic.ini -> BentoML-0.5.2+144.g2865d83/bentoml\n",
      "copying bentoml/db.py -> BentoML-0.5.2+144.g2865d83/bentoml\n",
      "copying bentoml/exceptions.py -> BentoML-0.5.2+144.g2865d83/bentoml\n",
      "copying bentoml/service.py -> BentoML-0.5.2+144.g2865d83/bentoml\n",
      "copying bentoml/service_env.py -> BentoML-0.5.2+144.g2865d83/bentoml\n",
      "copying bentoml/artifact/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/fastai_model_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/h2o_model_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/keras_model_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/lightgbm_model_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/pickle_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/pytorch_model_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/sklearn_model_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/text_file_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/tf_savedmodel_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/artifact/xgboost_model_artifact.py -> BentoML-0.5.2+144.g2865d83/bentoml/artifact\n",
      "copying bentoml/bundler/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/bundler\n",
      "copying bentoml/bundler/bundler.py -> BentoML-0.5.2+144.g2865d83/bentoml/bundler\n",
      "copying bentoml/bundler/config.py -> BentoML-0.5.2+144.g2865d83/bentoml/bundler\n",
      "copying bentoml/bundler/loader.py -> BentoML-0.5.2+144.g2865d83/bentoml/bundler\n",
      "copying bentoml/bundler/py_module_utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/bundler\n",
      "copying bentoml/bundler/templates.py -> BentoML-0.5.2+144.g2865d83/bentoml/bundler\n",
      "copying bentoml/bundler/utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/bundler\n",
      "copying bentoml/cli/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/cli/aws_lambda.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/cli/aws_sagemaker.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/cli/bento.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/cli/click_utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/cli/config.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/cli/deployment.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/cli/utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/cli/yatai_service.py -> BentoML-0.5.2+144.g2865d83/bentoml/cli\n",
      "copying bentoml/clipper/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/clipper\n",
      "copying bentoml/configuration/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/configuration\n",
      "copying bentoml/configuration/configparser.py -> BentoML-0.5.2+144.g2865d83/bentoml/configuration\n",
      "copying bentoml/configuration/default_bentoml.cfg -> BentoML-0.5.2+144.g2865d83/bentoml/configuration\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-36.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-37.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-38.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-36.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-37.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-38.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/configuration/__pycache__\n",
      "copying bentoml/deployment/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment\n",
      "copying bentoml/deployment/operator.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment\n",
      "copying bentoml/deployment/store.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment\n",
      "copying bentoml/deployment/utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment\n",
      "copying bentoml/deployment/aws_lambda/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/aws_lambda/download_extra_resources.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/aws_lambda/lambda_app.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/aws_lambda/utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/sagemaker/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment/sagemaker\n",
      "copying bentoml/deployment/sagemaker/sagemaker_nginx.conf -> BentoML-0.5.2+144.g2865d83/bentoml/deployment/sagemaker\n",
      "copying bentoml/deployment/sagemaker/sagemaker_serve.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment/sagemaker\n",
      "copying bentoml/deployment/sagemaker/sagemaker_wsgi.py -> BentoML-0.5.2+144.g2865d83/bentoml/deployment/sagemaker\n",
      "copying bentoml/handlers/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/base_handlers.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/clipper_handler.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/dataframe_handler.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/fastai_image_handler.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/image_handler.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/json_handler.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/pytorch_tensor_handler.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/tensorflow_tensor_handler.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/handlers/utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/handlers\n",
      "copying bentoml/marshal/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/marshal\n",
      "copying bentoml/marshal/dispatcher.py -> BentoML-0.5.2+144.g2865d83/bentoml/marshal\n",
      "copying bentoml/marshal/marshal.py -> BentoML-0.5.2+144.g2865d83/bentoml/marshal\n",
      "copying bentoml/marshal/utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/marshal\n",
      "copying bentoml/migrations/README -> BentoML-0.5.2+144.g2865d83/bentoml/migrations\n",
      "copying bentoml/migrations/env.py -> BentoML-0.5.2+144.g2865d83/bentoml/migrations\n",
      "copying bentoml/migrations/script.py.mako -> BentoML-0.5.2+144.g2865d83/bentoml/migrations\n",
      "copying bentoml/migrations/__pycache__/env.cpython-36.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/migrations/__pycache__\n",
      "copying bentoml/migrations/__pycache__/env.cpython-37.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/migrations/__pycache__\n",
      "copying bentoml/migrations/versions/a6b00ae45279_add_last_updated_at_for_deployments.py -> BentoML-0.5.2+144.g2865d83/bentoml/migrations/versions\n",
      "copying bentoml/migrations/versions/__pycache__/a6b00ae45279_add_last_updated_at_for_deployments.cpython-36.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/migrations/versions/__pycache__\n",
      "copying bentoml/migrations/versions/__pycache__/a6b00ae45279_add_last_updated_at_for_deployments.cpython-37.pyc -> BentoML-0.5.2+144.g2865d83/bentoml/migrations/versions/__pycache__\n",
      "copying bentoml/proto/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/proto\n",
      "copying bentoml/proto/deployment_pb2.py -> BentoML-0.5.2+144.g2865d83/bentoml/proto\n",
      "copying bentoml/proto/repository_pb2.py -> BentoML-0.5.2+144.g2865d83/bentoml/proto\n",
      "copying bentoml/proto/status_pb2.py -> BentoML-0.5.2+144.g2865d83/bentoml/proto\n",
      "copying bentoml/proto/yatai_service_pb2.py -> BentoML-0.5.2+144.g2865d83/bentoml/proto\n",
      "copying bentoml/proto/yatai_service_pb2_grpc.py -> BentoML-0.5.2+144.g2865d83/bentoml/proto\n",
      "copying bentoml/repository/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/repository\n",
      "copying bentoml/repository/metadata_store.py -> BentoML-0.5.2+144.g2865d83/bentoml/repository\n",
      "copying bentoml/server/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "copying bentoml/server/bento_api_server.py -> BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "copying bentoml/server/bento_sagemaker_server.py -> BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "copying bentoml/server/gunicorn_config.py -> BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "copying bentoml/server/gunicorn_server.py -> BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "copying bentoml/server/marshal_server.py -> BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "copying bentoml/server/middlewares.py -> BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "copying bentoml/server/utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/server\n",
      "copying bentoml/server/static/swagger-ui-bundle.js -> BentoML-0.5.2+144.g2865d83/bentoml/server/static\n",
      "copying bentoml/server/static/swagger-ui.css -> BentoML-0.5.2+144.g2865d83/bentoml/server/static\n",
      "copying bentoml/utils/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/cloudpickle.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/hybirdmethod.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/log.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/pip_pkg.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/s3.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/tempdir.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/trace.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/usage_stats.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils\n",
      "copying bentoml/utils/validator/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/utils/validator\n",
      "copying bentoml/yatai/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/yatai\n",
      "copying bentoml/yatai/deployment_utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/yatai\n",
      "copying bentoml/yatai/status.py -> BentoML-0.5.2+144.g2865d83/bentoml/yatai\n",
      "copying bentoml/yatai/utils.py -> BentoML-0.5.2+144.g2865d83/bentoml/yatai\n",
      "copying bentoml/yatai/yatai_service_impl.py -> BentoML-0.5.2+144.g2865d83/bentoml/yatai\n",
      "copying bentoml/yatai/client/__init__.py -> BentoML-0.5.2+144.g2865d83/bentoml/yatai/client\n",
      "copying bentoml/yatai/client/bento_repository_api.py -> BentoML-0.5.2+144.g2865d83/bentoml/yatai/client\n",
      "copying bentoml/yatai/client/deployment_api.py -> BentoML-0.5.2+144.g2865d83/bentoml/yatai/client\n",
      "Writing BentoML-0.5.2+144.g2865d83/setup.cfg\n",
      "UPDATING BentoML-0.5.2+144.g2865d83/bentoml/_version.py\n",
      "set BentoML-0.5.2+144.g2865d83/bentoml/_version.py to '0.5.2+144.g2865d83'\n",
      "Creating tar archive\n",
      "removing 'BentoML-0.5.2+144.g2865d83' (and everything under it)\n",
      "[2020-03-24 22:29:49,974] INFO - BentoService bundle 'BentoSvc:20200324222939_C004B4' created at: /tmp/bentoml-temp-owyu991f\n",
      "[2020-03-24 22:29:49,975] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.5.2. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-03-24 22:29:49,989] WARNING - Saved BentoService bundle version mismatch: loading BentoServie bundle create with BentoML version 0.5.2,  but loading from BentoML version 0.5.2+144.g2865d83\n",
      "[2020-03-24 22:29:50,009] INFO - BentoService bundle 'BentoSvc:20200324222939_C004B4' saved to: /home/bentoml/bentoml/repository/BentoSvc/20200324222939_C004B4\n"
     ]
    }
   ],
   "source": [
    "from linear_sleep import BentoSvc\n",
    "\n",
    "bento_svc = BentoSvc()\n",
    "bento_svc.pack(\"model\", model)\n",
    "saved_path = bento_svc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52565\n"
     ]
    }
   ],
   "source": [
    "from bentoml.utils import detect_free_port\n",
    "PORT = detect_free_port()\n",
    "print(PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bentoml serve-gunicorn /home/bentoml/bentoml/repository/BentoSvc/20200324222939_C004B4 --port 52565 --workers 1 --enable-microbatch\n",
      "[2020-03-24 22:29:52,516] INFO - Running micro batch service on :52565\n",
      "[2020-03-24 22:29:53 +0800] [1965917] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-03-24 22:29:53 +0800] [1965917] [INFO] Listening at: http://0.0.0.0:59881 (1965917)\n",
      "[2020-03-24 22:29:53 +0800] [1965917] [INFO] Using worker: sync\n",
      "[2020-03-24 22:29:53 +0800] [1966251] [INFO] Booting worker with pid: 1966251\n",
      "[2020-03-24 22:29:53 +0800] [1966051] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-03-24 22:29:53 +0800] [1966051] [INFO] Listening at: http://0.0.0.0:52565 (1966051)\n",
      "[2020-03-24 22:29:53 +0800] [1966051] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n",
      "[2020-03-24 22:29:53 +0800] [1966252] [INFO] Booting worker with pid: 1966252\n",
      "[2020-03-24 22:29:53,898] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.5.2. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-03-24 22:29:53,912] WARNING - Saved BentoService bundle version mismatch: loading BentoServie bundle create with BentoML version 0.5.2,  but loading from BentoML version 0.5.2+144.g2865d83\n",
      "[2020-03-24 22:29:53,913] INFO - Micro batch enabled for API `predict`\n",
      "[2020-03-24 22:29:53,914] INFO - Your system nofile limit is 1024, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
      "[2020-03-24 22:29:55,345] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.5.2. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-03-24 22:29:55,358] WARNING - Saved BentoService bundle version mismatch: loading BentoServie bundle create with BentoML version 0.5.2,  but loading from BentoML version 0.5.2+144.g2865d83\n",
      "[2020-03-24 22:29:55,364] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.5.2. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-03-24 22:29:55,712] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.5.2. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "^C\n",
      "[2020-03-24 22:46:13 +0800] [1966252] [INFO] Worker exiting (pid: 1966252)\n",
      "[2020-03-24 22:46:13 +0800] [1966051] [INFO] Handling signal: int\n",
      "[2020-03-24 22:46:13 +0800] [1965917] [INFO] Handling signal: int\n",
      "[2020-03-24 22:46:13 +0800] [1966051] [INFO] Shutting down: Master\n",
      "[2020-03-24 22:46:13 +0800] [1966251] [INFO] Worker exiting (pid: 1966251)\n"
     ]
    }
   ],
   "source": [
    "print(f\"bentoml serve-gunicorn {saved_path} --port {PORT} --workers 1 --enable-microbatch\")\n",
    "!bentoml serve-gunicorn {saved_path} --port {PORT} --workers 1 --enable-microbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build & Run Bento Service in Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {saved_path}\n",
    "IMG_NAME = saved_path.split('/')[-1].lower()\n",
    "!docker build -t {IMG_NAME} \\\n",
    "    --build-arg PIP_TRUSTED_HOST=192.168.138.2 \\  # set your prefer PYPI mirror\n",
    "    --build-arg PIP_INDEX_URL=http://192.168.138.2/simple \\\n",
    "    {saved_path}\n",
    "!docker run -itd -p {PORT}:5000 --cpus 1 -e FLAGS=\"--workers 1 --enable-microbatch\" {IMG_NAME}:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "data = pd.DataFrame([[0.0, 2.0]]).to_json()\n",
    "print(data)\n",
    "\n",
    "json_response = requests.post(f'http://127.0.0.1:{PORT}/predict',\n",
    "                              data=data, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark with locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile benchmark_{NAME}.py\n",
    "from locust import HttpLocust, TaskSet, task, constant\n",
    "from functools import lru_cache\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "A = float(os.environ.get('A', 0))\n",
    "B = float(os.environ.get('B', 0))\n",
    "WAIT = float(os.environ.get('WAIT', 1))\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def data_producer():\n",
    "\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "    def _gen_data():\n",
    "        _A = A + random.random() / 100000.0\n",
    "        _B = B + random.random() / 10000.0\n",
    "        data = pd.DataFrame([[_A, _B]]).to_json()\n",
    "        return headers, data\n",
    "\n",
    "    return _gen_data\n",
    "\n",
    "\n",
    "class WebsiteTasks(TaskSet):\n",
    "\n",
    "    @task\n",
    "    def index(self):\n",
    "        headers, data = data_producer()()\n",
    "        self.client.post(\"/predict\", data, headers=headers)\n",
    "\n",
    "class WebsiteUser(HttpLocust):\n",
    "    task_set = WebsiteTasks\n",
    "    wait_time = constant(WAIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"locust -f benchmark_{NAME}.py -H http://127.0.0.1:{PORT} --port 8090\")\n",
    "!locust -f benchmark_{NAME}.py -H http://127.0.0.1:{PORT} --port 8090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "bentoml-dev-py36",
   "language": "python",
   "name": "bentoml-dev-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
