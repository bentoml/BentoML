{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with BentoML\n",
    "\n",
    "[BentoML](http://bentoml.ai) is an open source framework for serving and deploying machine learning models. It provides high-level APIs for defining a prediction service and packaging trained models, source code, dependencies, and configurations into a production-system-friendly format that is ready for production deployment.\n",
    "\n",
    "This is a quick tutorial on how to use BentoML to create a prediction service with a trained sklearn model, serving the model via a REST API server and deploy it to [AWS Lambda](https://aws.amazon.com/lambda/) as a serverless endpoint.\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=guides&ea=bentoml-quick-start-guide&dt=bentoml-quick-start-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install BentoML\n",
    "!pip install bentoml\n",
    "\n",
    "# Install scikit-learn, we will use a sklean model as an example\n",
    "!pip install pandas sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started with a simple scikit-learn model as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "\n",
    "clf = svm.SVC(gamma='scale')\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BentoService for model serving\n",
    "\n",
    "To package this trained model for model serving in production, you will need to create a custom BentoService class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting iris_classifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier.py\n",
    "from bentoml import BentoService, api, env, artifacts\n",
    "from bentoml.artifact import SklearnModelArtifact\n",
    "from bentoml.handlers import DataframeHandler\n",
    "\n",
    "@artifacts([SklearnModelArtifact('model')])\n",
    "@env(pip_dependencies=[\"scikit-learn\"])\n",
    "class IrisClassifier(BentoService):\n",
    "\n",
    "    @api(DataframeHandler)\n",
    "    def predict(self, df):\n",
    "        return self.artifacts.model.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@artifacts` decorator here tells BentoML what artifacts are required when \n",
    "packaging this BentoService. Besides `SklearnModelArtifact`, BentoML also provides\n",
    "`KerasModelArtifact`, `PytorchModelArtifact`, `FastaiModelArtifact` and \n",
    "`PickleArtifact` etc.\n",
    "\n",
    "`@env` is designed for specifying the desired system environment in order for this\n",
    "BentoService to load. If you already have a requirement.txt file listing all python \n",
    "libraries you need:\n",
    "```python\n",
    "@env(requirement_txt='../myproject/requirement.txt')\n",
    "```\n",
    "\n",
    "Lastly `@api` adds an entry point for accessing this BentoService. Each\n",
    "`api` will be translated into a REST endpoint when [deploying as API\n",
    "server](#serving-via-rest-api), or a CLI command when [running as a CLI\n",
    "tool](#use-as-cli-tool).\n",
    "\n",
    "Each API also requires a `Handler` for defining the expected input format. In\n",
    "this case, `DataframeHandler` will transform either an HTTP request or CLI\n",
    "command arguments into a pandas Dataframe and pass it down to the user defined\n",
    "API function. BentoML also supports `JsonHandler`, `ImageHandler` and\n",
    "`TensorHandler`.\n",
    "\n",
    "\n",
    "## Save BentoService to file archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-15 12:30:56,177] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.4.9. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2019-11-15 12:31:20,006] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.4.9. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "running sdist\n",
      "running egg_info\n",
      "writing BentoML.egg-info/PKG-INFO\n",
      "writing dependency_links to BentoML.egg-info/dependency_links.txt\n",
      "writing entry points to BentoML.egg-info/entry_points.txt\n",
      "writing requirements to BentoML.egg-info/requires.txt\n",
      "writing top-level names to BentoML.egg-info/top_level.txt\n",
      "reading manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no previously-included directories found matching 'examples'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'docs'\n",
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/BentoML.egg-info\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/bundler\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/cli\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/clipper\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/configuration\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/aws_lambda\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/sagemaker\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/serverless\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/migrations\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/migrations/versions\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/proto\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/repository\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/server\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/server/static\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils/validator\n",
      "creating BentoML-0.4.9+19.g83f8720.dirty/bentoml/yatai\n",
      "copying files to BentoML-0.4.9+19.g83f8720.dirty...\n",
      "copying LICENSE -> BentoML-0.4.9+19.g83f8720.dirty\n",
      "copying MANIFEST.in -> BentoML-0.4.9+19.g83f8720.dirty\n",
      "copying README.md -> BentoML-0.4.9+19.g83f8720.dirty\n",
      "copying setup.cfg -> BentoML-0.4.9+19.g83f8720.dirty\n",
      "copying setup.py -> BentoML-0.4.9+19.g83f8720.dirty\n",
      "copying versioneer.py -> BentoML-0.4.9+19.g83f8720.dirty\n",
      "copying BentoML.egg-info/PKG-INFO -> BentoML-0.4.9+19.g83f8720.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/SOURCES.txt -> BentoML-0.4.9+19.g83f8720.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/dependency_links.txt -> BentoML-0.4.9+19.g83f8720.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/entry_points.txt -> BentoML-0.4.9+19.g83f8720.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/requires.txt -> BentoML-0.4.9+19.g83f8720.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/top_level.txt -> BentoML-0.4.9+19.g83f8720.dirty/BentoML.egg-info\n",
      "copying bentoml/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml\n",
      "copying bentoml/_version.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml\n",
      "copying bentoml/alembic.ini -> BentoML-0.4.9+19.g83f8720.dirty/bentoml\n",
      "copying bentoml/db.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml\n",
      "copying bentoml/exceptions.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml\n",
      "copying bentoml/service.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml\n",
      "copying bentoml/service_env.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml\n",
      "copying bentoml/artifact/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/fastai_model_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/h2o_model_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/keras_model_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/pickle_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/pytorch_model_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/sklearn_model_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/text_file_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/tf_savedmodel_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/xgboost_model_artifact.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/artifact\n",
      "copying bentoml/bundler/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/bundler.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/config.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/loader.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/py_module_utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/templates.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/bundler\n",
      "copying bentoml/cli/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/cli\n",
      "copying bentoml/cli/click_utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/cli\n",
      "copying bentoml/cli/config.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/cli\n",
      "copying bentoml/cli/deployment.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/cli\n",
      "copying bentoml/cli/utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/cli\n",
      "copying bentoml/clipper/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/clipper\n",
      "copying bentoml/configuration/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/configuration\n",
      "copying bentoml/configuration/configparser.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/configuration\n",
      "copying bentoml/configuration/default_bentoml.cfg -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/configuration\n",
      "copying bentoml/deployment/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment\n",
      "copying bentoml/deployment/operator.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment\n",
      "copying bentoml/deployment/store.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment\n",
      "copying bentoml/deployment/utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment\n",
      "copying bentoml/deployment/aws_lambda/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/aws_lambda/utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/sagemaker/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/sagemaker\n",
      "copying bentoml/deployment/sagemaker/templates.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/sagemaker\n",
      "copying bentoml/deployment/serverless/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/serverless\n",
      "copying bentoml/deployment/serverless/aws_lambda.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/serverless\n",
      "copying bentoml/deployment/serverless/gcp_function.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/serverless\n",
      "copying bentoml/deployment/serverless/serverless_utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/deployment/serverless\n",
      "copying bentoml/handlers/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/base_handlers.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/clipper_handler.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/dataframe_handler.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/fastai_image_handler.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/image_handler.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/json_handler.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/pytorch_tensor_handler.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/tensorflow_tensor_handler.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/handlers\n",
      "copying bentoml/migrations/README -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/migrations\n",
      "copying bentoml/migrations/env.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/migrations\n",
      "copying bentoml/migrations/script.py.mako -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/migrations\n",
      "copying bentoml/migrations/versions/a6b00ae45279_add_last_updated_at_for_deployments.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/migrations/versions\n",
      "copying bentoml/proto/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/proto\n",
      "copying bentoml/proto/deployment_pb2.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/proto\n",
      "copying bentoml/proto/repository_pb2.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/proto\n",
      "copying bentoml/proto/status_pb2.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/proto\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying bentoml/proto/yatai_service_pb2.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/proto\n",
      "copying bentoml/proto/yatai_service_pb2_grpc.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/proto\n",
      "copying bentoml/repository/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/repository\n",
      "copying bentoml/repository/metadata_store.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/repository\n",
      "copying bentoml/server/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/server\n",
      "copying bentoml/server/bento_api_server.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/server\n",
      "copying bentoml/server/bento_sagemaker_server.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/server\n",
      "copying bentoml/server/gunicorn_server.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/server\n",
      "copying bentoml/server/metrics.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/server\n",
      "copying bentoml/server/utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/server\n",
      "copying bentoml/server/static/swagger-ui-bundle.js -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/server/static\n",
      "copying bentoml/server/static/swagger-ui.css -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/server/static\n",
      "copying bentoml/utils/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "copying bentoml/utils/cloudpickle.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "copying bentoml/utils/hybirdmethod.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "copying bentoml/utils/log.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "copying bentoml/utils/s3.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "copying bentoml/utils/tempdir.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "copying bentoml/utils/usage_stats.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "copying bentoml/utils/whichcraft.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils\n",
      "copying bentoml/utils/validator/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/utils/validator\n",
      "copying bentoml/yatai/__init__.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/yatai\n",
      "copying bentoml/yatai/deployment_utils.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/yatai\n",
      "copying bentoml/yatai/python_api.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/yatai\n",
      "copying bentoml/yatai/status.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/yatai\n",
      "copying bentoml/yatai/yatai_service_impl.py -> BentoML-0.4.9+19.g83f8720.dirty/bentoml/yatai\n",
      "Writing BentoML-0.4.9+19.g83f8720.dirty/setup.cfg\n",
      "UPDATING BentoML-0.4.9+19.g83f8720.dirty/bentoml/_version.py\n",
      "set BentoML-0.4.9+19.g83f8720.dirty/bentoml/_version.py to '0.4.9+19.g83f8720.dirty'\n",
      "Creating tar archive\n",
      "removing 'BentoML-0.4.9+19.g83f8720.dirty' (and everything under it)\n",
      "[2019-11-15 12:31:21,450] INFO - BentoService bundle 'IrisClassifier:20191115123056_BC895A' created at: /private/var/folders/kn/xnc9k74x03567n1mx2tfqnpr0000gn/T/bentoml-temp-vx5ms9xt\n",
      "[2019-11-15 12:31:21,452] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.4.9. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2019-11-15 12:31:21,463] WARNING - Saved BentoService bundle version mismatch: loading BentoServie bundle create with BentoML version 0.4.9,  but loading from BentoML version 0.4.9+19.g83f8720.dirty\n",
      "[2019-11-15 12:31:21,653] INFO - BentoService bundle 'IrisClassifier:20191115123056_BC895A' created at: /Users/bozhaoyu/bentoml/repository/IrisClassifier/20191115123056_BC895A\n"
     ]
    }
   ],
   "source": [
    "# 1) import the custom BentoService defined above\n",
    "from iris_classifier import IrisClassifier\n",
    "\n",
    "# 2) `pack` it with required artifacts\n",
    "svc = IrisClassifier.pack(model=clf)\n",
    "\n",
    "# 3) save BentoSerivce to a BentoML bundle\n",
    "saved_path = svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_That's it._ You've just created your first BentoML Bundle. It's a versioned file archive, containing the BentoService you defined, including the trained model, dependencies and configurations etc, everything it needs to deploy the exact same service in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Serving via REST API\n",
    "\n",
    "Use the `bentoml serve` command to start a REST API server from a saved BentoML bundle. This allows application developers to easily intergrate with the ML model you are developing.\n",
    "\n",
    "Note that REST API serving **does not work in Google Colab**, due to unable to access Colab's VM. You may download the notebook and run it locally to play with the BentoML API server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!bentoml serve {saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View documentations for REST APIs\n",
    "\n",
    "Open http://127.0.0.1:5000 to see more information about the REST APIs server in your\n",
    "browser.\n",
    "\n",
    "#### Send prediction request to REST API server\n",
    "\n",
    "*Run the following command in terminal to make a HTTP request to the API server*\n",
    "```bash\n",
    "curl -i \\\n",
    "--header \"Content-Type: application/json\" \\\n",
    "--request POST \\\n",
    "--data '[[5.1, 3.5, 1.4, 0.2]]' \\\n",
    "localhost:5000/predict\n",
    "```\n",
    "\n",
    "Note you must ensure the pip and conda dependencies are available in your python\n",
    "environment when using `bentoml serve` command. More commonly we recommend using\n",
    "BentoML API server with Docker:\n",
    "\n",
    "## Run REST API server with Docker\n",
    "\n",
    "BentoML supports building Docker Image for your REST API model server.\n",
    "Simply use the BentoML bundle directory as the docker build context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {saved_path} && docker build -t iris-classifier ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `docker` is __note available in Google Colab__, download the notebook, ensure docker is installed and try it locally.\n",
    "\n",
    "Next, you can `docker push` the image to your choice of registry for deployment,\n",
    "or run it locally for development and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 5000:5000 iris-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved BentoService\n",
    "\n",
    "`bentoml.load` is the enssential API for loading a Bento into your\n",
    "python application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import pandas as pd\n",
    "\n",
    "bento_svc = bentoml.load(saved_path)\n",
    "\n",
    "# Test loaded bentoml service:\n",
    "bento_svc.predict([X[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"pip install\" a BentoML bundle\n",
    "\n",
    "BentoML also supports distributing a BentoService as PyPI package, with the\n",
    "generated `setup.py` file. A Bento directory can be installed with `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install {saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can import your ML service as a regular python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IrisClassifier\n",
    "\n",
    "installed_svc = IrisClassifier.load()\n",
    "installed_svc.predict([X[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bento PyPI package can also be uploaded to pypi.org\n",
    "as a public python package, or to your organization's private PyPI index for all\n",
    "developers in your organization to use:\n",
    "\n",
    "`cd {saved_path} & python setup.py sdist upload`\n",
    "\n",
    "*You will need a \".pypirc\" config file before doing this: https://docs.python.org/2/distutils/packageindex.html*\n",
    "\n",
    "\n",
    "# CLI access\n",
    "\n",
    "`pip install {saved_path}` also installs a CLI tool for accessing the BentoML service, print CLI help document with `--help`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!IrisClassifier --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing more information about this ML service with `info` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!IrisClassifier info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also print help and docs on individual commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!IrisClassifier predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each service API you defined in the BentoService will be exposed as a CLI command with the same name as the API function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!IrisClassifier predict --input='[[5.1, 3.5, 1.4, 0.2]]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BentoML cli also supports reading input data from `csv` or `json` files, in either local machine or remote HTTP/S3 location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing test data to a csv file\n",
    "pd.DataFrame(iris.data).to_csv('iris_data.csv', index=False)\n",
    "\n",
    "# Invoke predict from command lien\n",
    "!IrisClassifier predict --input='./iris_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also use the `bentoml` cli to load and run a BentoML service archive without installing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml info {saved_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml predict {saved_path} --input='[[5.1, 3.5, 1.4, 0.2]]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying to AWS Lambda\n",
    "\n",
    "AWS Lambda is a serverless computing platform provided by Amazon Web Services. BentoML service archive can be easily deployed to AWS Lambda as a REST API endpoint.\n",
    "\n",
    "In order to run this demo, make sure to configure your AWS credentials via either `aws configure` command or setting the environment variables below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env AWS_ACCESS_KEY_ID=\n",
    "%env AWS_SECRET_ACCESS_KEY="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have [nodejs](https://nodejs.org) installed on your machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!node --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can deploy the BentML bundle you just created to AWS Lambda with one command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!bentoml deployment create quick-start-guide-deployment \\\n",
    "    --bento=IrisClassifier:{svc.version} \\\n",
    "    --api-name=predict \\\n",
    "    --platform=aws-lambda \\\n",
    "    --region=us-west-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the 'quick-starrt-guide-deployment' is the deployment name, you can reference the deployment by this name and query its status. For example, to get current deployment status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!bentoml deployment describe quick-start-guide-deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view your deployment configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml deployment get quick-start-guide-deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to delete an active deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml deployment delete quick-start-guide-deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BentoML by default stores the deployment metadata on the local machine. For team settings, we recommend hosting a shared BentoML Yatai server for your entire team to track all the BentoML bundle and deployments they've created in a central place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This is what it looks like when using BentoML to create and deploy a machine learning service, all the way from training notebook to deployment in production. BentoML also supports many other Machine Learning frameworks, as well as many other deployment platforms. Take a look at other BentoML examples [here](https://github.com/bentoml/BentoML#examples)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
