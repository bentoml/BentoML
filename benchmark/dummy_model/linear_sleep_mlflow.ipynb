{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# add venv PATH to shell command PATH\n",
    "import sys, os\n",
    "if sys.base_prefix not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = f\"{sys.base_prefix}/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'linear_sleep_mlflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & train model(not used, just placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  [2.   1.   0.   1.   1.67 0.   1.24 1.   0.   1.   2.   1.   0.   2.\n",
      " 0.   1.93 2.   2.   0.   0.   1.   2.   1.   1.31 1.48 1.93 1.   1.\n",
      " 2.   2.  ]\n",
      "  mse: 0.092760\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, 2:]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)\n",
    "\n",
    "    \n",
    "# add parameters for tuning\n",
    "num_estimators = 100\n",
    "\n",
    "# train the model\n",
    "rf = RandomForestRegressor(n_estimators=num_estimators)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print('predictions: ', predictions)\n",
    "\n",
    "# log model performance \n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"  mse: %f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tmpdir = 'mlflow_tmp'\n",
    "data_path = os.path.join(tmpdir, 'skmodel.pkl')\n",
    "with open(data_path, 'wb') as of:\n",
    "    pickle.dump(rf, of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting linear_sleep_mlflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {NAME}.py\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import six\n",
    "import time\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.pyfunc.model\n",
    "from mlflow.models import Model\n",
    "\n",
    "\n",
    "def _load_pyfunc(path):\n",
    "    with open(path, 'rb') as of:\n",
    "        data_model = pickle.load(of)\n",
    "    class Model:\n",
    "        def predict(self, inputs):\n",
    "            a, b = inputs.to_numpy()[0]\n",
    "            x = inputs.shape[0]\n",
    "            time.sleep(a * x + b)\n",
    "            return inputs\n",
    "    return Model()\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tmpdir = 'mlflow_tmp'\n",
    "    data_path = os.path.join(tmpdir, 'skmodel.pkl')\n",
    "    model_path = os.path.join(str(tmpdir), \"model\")\n",
    "\n",
    "    model_config = Model(run_id=\"test\")\n",
    "    mlflow.pyfunc.save_model(path=model_path,\n",
    "                             data_path=data_path,\n",
    "                             loader_module=os.path.basename(__file__)[:-3],\n",
    "                             code_path=[__file__],\n",
    "                             mlflow_model=model_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bentoml-dev-py36/lib/python3.6/site-packages/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/anaconda3/envs/bentoml-dev-py36/lib/python3.6/site-packages/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2020/03/26 17:48:17 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
      "2020/03/26 17:48:17 INFO mlflow.pyfunc.backend: === Running command 'gunicorn --timeout=60 -b 127.0.0.1:5000 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2020-03-26 17:48:17 +0800] [3262602] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-03-26 17:48:17 +0800] [3262602] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
      "[2020-03-26 17:48:17 +0800] [3262602] [ERROR] Retrying in 1 second.\n",
      "[2020-03-26 17:48:18 +0800] [3262602] [INFO] Listening at: http://127.0.0.1:5000 (3262602)\n",
      "[2020-03-26 17:48:18 +0800] [3262602] [INFO] Using worker: sync\n",
      "[2020-03-26 17:48:18 +0800] [3262614] [INFO] Booting worker with pid: 3262614\n",
      "/opt/anaconda3/envs/bentoml-dev-py36/lib/python3.6/site-packages/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "^C\n",
      "\n",
      "Aborted!\n",
      "[2020-03-26 18:06:30 +0800] [3262602] [INFO] Handling signal: int\n",
      "[2020-03-26 18:06:31 +0800] [3262614] [INFO] Worker exiting (pid: 3262614)\n"
     ]
    }
   ],
   "source": [
    "!rm -r {tmpdir}/model\n",
    "!python {NAME}.py\n",
    "!mlflow models serve -m {tmpdir}/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[{'0': 0, '1': 2}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "raw_data = np.array([[0, 2]])\n",
    "data = pd.DataFrame(raw_data,\n",
    "                    columns=map(str, range(raw_data.shape[1]))).to_json(orient='split')\n",
    "\n",
    "json_response = requests.post(f'http://127.0.0.1:5000/invocations',\n",
    "                              data=data, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark with locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting benchmark_linear_sleep_mlflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile benchmark_{NAME}.py\n",
    "from locust import HttpLocust, TaskSet, task, constant\n",
    "from functools import lru_cache\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "A = float(os.environ.get('A', 0))\n",
    "B = float(os.environ.get('B', 0))\n",
    "WAIT = float(os.environ.get('WAIT', 1))\n",
    "\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def data_producer():\n",
    "\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "    def _gen_data():\n",
    "        _A = A + random.random() / 100000.0\n",
    "        _B = B + random.random() / 10000.0\n",
    "\n",
    "        raw_data = np.array([[_A, _B]])\n",
    "        data = pd.DataFrame(raw_data,columns=map(str, range(raw_data.shape[1]))).to_json(orient='split')\n",
    "        return headers, data\n",
    "\n",
    "    return _gen_data\n",
    "\n",
    "\n",
    "class WebsiteTasks(TaskSet):\n",
    "\n",
    "    @task\n",
    "    def index(self):\n",
    "        headers, data = data_producer()()\n",
    "        self.client.post(\"/invocations\", data, headers=headers)\n",
    "\n",
    "class WebsiteUser(HttpLocust):\n",
    "    task_set = WebsiteTasks\n",
    "    wait_time = constant(WAIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-26 17:47:23,562] beta/INFO/locust.main: Starting web monitor at http://*:8089\n",
      "[2020-03-26 17:47:23,562] beta/INFO/locust.main: Starting Locust 0.14.4\n",
      "[2020-03-26 17:47:46,973] beta/INFO/locust.runners: Hatching and swarming 10 users at the rate 1 users/s (0 users already running)...\n",
      "[2020-03-26 17:47:55,983] beta/INFO/locust.runners: All locusts hatched: WebsiteUser: 10 (0 already running)\n",
      "^C\n",
      "[2020-03-26 17:48:08,198] beta/ERROR/stderr: KeyboardInterrupt\n",
      "[2020-03-26 17:48:08,198] beta/ERROR/stderr: 2020-03-26T09:48:08Z\n",
      "[2020-03-26 17:48:08,198] beta/ERROR/stderr: \n",
      "[2020-03-26 17:48:08,198] beta/INFO/locust.main: Shutting down (exit code 0), bye.\n",
      "[2020-03-26 17:48:08,198] beta/INFO/locust.main: Cleaning up runner...\n",
      "[2020-03-26 17:48:08,199] beta/INFO/locust.main: Running teardowns...\n",
      " Name                                                          # reqs      # fails     Avg     Min     Max  |  Median   req/s failures/s\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      " POST /invocations                                                125     0(0.00%)       7       3      19  |       6    7.72    0.00\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      " Aggregated                                                       125     0(0.00%)       7       3      19  |       6    7.72    0.00\n",
      "\n",
      "Percentage of the requests completed within given times\n",
      " Type                 Name                                                           # reqs    50%    66%    75%    80%    90%    95%    98%    99%  99.9% 99.99%   100%\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " POST                 /invocations                                                      125      6      9      9     10     12     13     17     17     19     19     19\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " None                 Aggregated                                                        125      6      9      9     10     12     13     17     17     19     19     19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!locust -f benchmark_{NAME}.py -H http://127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "bentoml-dev-py36",
   "language": "python",
   "name": "bentoml-dev-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
