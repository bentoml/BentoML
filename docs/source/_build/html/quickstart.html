
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Quick Start &#8212; BentoML  documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="CLI" href="cli.html" />
    <link rel="prev" title="BentoML Documentation" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="quick-start">
<h1>Quick Start<a class="headerlink" href="#quick-start" title="Permalink to this headline">¶</a></h1>
<div class="section" id="install-bentoml">
<h2>Install BentoML<a class="headerlink" href="#install-bentoml" title="Permalink to this headline">¶</a></h2>
<p>Install BentoML is straightforward.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">bentoml</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We recommend use conda to manage python environment</p>
</div>
</div>
<div class="section" id="running-the-quick-start-project">
<h2>Running the quick start project<a class="headerlink" href="#running-the-quick-start-project" title="Permalink to this headline">¶</a></h2>
<p>The easiest way to try out the quick start project is using Google’s Colab to run the
quick start project. You can use this <a class="reference external" href="http://bit.ly/2ID50XP">link</a> to launch it from your browser</p>
<p>You can also run the quick start project locally. Download the quick start
example by git clone the BentoML repo, and navigate to the quick start project
inside the <cite>example</cite> folder</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ pip install jupyter
$ git clone http://github.com/bentoml/bentoml
$ <span class="nb">cd</span> bentoml/examples/quick-start
$ jupyter notebook bentoml-quick-start-guide.ipynb
</pre></div>
</div>
<p>We will go through each cell inside the notebook with explanation follows
below.</p>
</div>
<div class="section" id="quick-start-walk-through">
<h2>Quick start walk through<a class="headerlink" href="#quick-start-walk-through" title="Permalink to this headline">¶</a></h2>
<div class="section" id="add-bentoml-to-the-notebook-and-training-classification-model">
<h3>Add BentoML to the notebook and training classification model<a class="headerlink" href="#add-bentoml-to-the-notebook-and-training-classification-model" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!pip install -I bentoml
!pip install pandas sklearn
</pre></div>
</div>
<p>We use jupyter notebook’s built-in magic command to download and install
python modules such as scikit-learn for our example model.
We also download and install BentoML for define ML service later on.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">)</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>We trained a classification model with scikit-learn’s iris dataset.</p>
</div>
<div class="section" id="define-machine-learning-service-with-bentoml">
<h3>Define machine learning service with BentoML<a class="headerlink" href="#define-machine-learning-service-with-bentoml" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">iris_classifier</span><span class="o">.</span><span class="n">py</span>
<span class="kn">from</span> <span class="nn">bentoml</span> <span class="kn">import</span> <span class="n">BentoService</span><span class="p">,</span> <span class="n">api</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">artifacts</span>
<span class="kn">from</span> <span class="nn">bentoml.artifact</span> <span class="kn">import</span> <span class="n">PickleArtifact</span>
<span class="kn">from</span> <span class="nn">bentoml.handlers</span> <span class="kn">import</span> <span class="n">DataframeHandler</span>

<span class="nd">@artifacts</span><span class="p">([</span><span class="n">PickleArtifact</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">)])</span>
<span class="nd">@env</span><span class="p">(</span><span class="n">conda_pip_dependencies</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;scikit-learn&quot;</span><span class="p">])</span>
<span class="k">class</span> <span class="nc">IrisClassifier</span><span class="p">(</span><span class="n">BentoService</span><span class="p">):</span>

    <span class="nd">@api</span><span class="p">(</span><span class="n">DataframeHandler</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">artifacts</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<p><strong>Line 1</strong>: We use jupyter notebook’s built-in magic command to save our ML
service definition into a python file</p>
<p><strong>Line 2</strong>: We import BentoService, our ML service will build on top of this
by subclassing it. We also import decorators such as, artifacts, api and env
for defining our ML service.</p>
<ul class="simple">
<li><p><strong>artifacts</strong> decorator define what artifacts are required for packaging
this service.</p></li>
<li><p><strong>env</strong> decorator designed for specifying the desired system environment
and dependencies in order for this service to load. For this project we
are using conda environment.  Other ways you can use this decorator:</p>
<ul>
<li><p>If you already have requirement.txt file listing all of the python
libraries you need:
<code class="docutils literal notranslate"><span class="pre">&#64;env(requirement_txt=&quot;../my_project/requirement.txt&quot;)</span></code></p></li>
<li><p>If you are running this code inside a conda environment that matches
the desired production environment:
<code class="docutils literal notranslate"><span class="pre">&#64;env(with_current_conda_env=True)</span></code></p></li>
</ul>
</li>
<li><p><strong>api</strong>: decorator allow us to add an entry point to accessing this service.
Each <em>api</em> will be translate into a REST endpoint when deploying as API
server, or a CLI command when running the service as CLI tool.</p></li>
</ul>
<dl class="simple">
<dt><strong>Line 3</strong>: Using <strong>PickleArtifact</strong> for packaging our classifier model. Beside</dt><dd><p>PickleArtifact, BentoML offers <cite>TfKerasModelArtifact</cite>,
<cite>PytorchModelArtifact</cite>, <cite>H2oModelArtifact</cite>, <cite>XgboostModelArtifact</cite> and etc.</p>
</dd>
<dt><strong>Line 4</strong>: Each API endpoint requires a Handler for defining the expect input</dt><dd><p>format. For this project, we are using <strong>DataframeHnalder</strong> to transform
either a HTTP request or CLI command argument into a pandas dataframe and
pass it down to the user defined API function. BentoML also provides
<cite>JsonHandler</cite>, <cite>ImageHandler</cite> and <cite>TensorHandler</cite></p>
</dd>
</dl>
<p><strong>Line 6-7</strong>: We defined what artifact need to be included for this service,
and giving it a name <cite>model</cite>, and include the  python library that we need
for this project.</p>
<p><strong>Line 8</strong>: We created our ML service called IrisClassifier by subclassing
<cite>BentoService</cite></p>
<p><strong>Line 10-12</strong>: We defined a function called <cite>predict</cite>. It will return result
from the artifact, <cite>model</cite>, we defined earlier by calling <cite>predict</cite> on that
artifact. We expose this predict function as our api for the service with the
<cite>api</cite> decorator, and tell BentoML that the incoming data will be transformed
into pandas dataframe for the user defined <cite>predict</cite> function to consume.</p>
<p>Now we have defined the ML service with BentoML, we will package our trained
model next and save it as archive to the file system.</p>
</div>
<div class="section" id="save-defined-ml-service-as-bentoml-service-archive">
<h3>Save defined ML service as BentoML service archive<a class="headerlink" href="#save-defined-ml-service-as-bentoml-service-archive" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">iris_classifier</span> <span class="kn">import</span> <span class="n">IrisClassifier</span>

<span class="n">svc</span> <span class="o">=</span> <span class="n">IrisClassifier</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">clf</span><span class="p">)</span>
<span class="n">saved_path</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/tmp/bentoml_archive&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">saved_path</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<p><strong>Line 1</strong>: We import the service definition we wrote in the previous cell.</p>
<p><strong>Line 3</strong>: We are packaging the trained model from above with the ML
service.</p>
<p><strong>Line 4-5</strong>: We saved the packed service as BentoML archive into the local
file system and print out the saved location path.</p>
<p>We just created and saved our quick start project into BentoML service archive.
It is a directory containing all of the source code, data, and configurations
that required to load and run as Bento Service. You will find three <cite>magic</cite>
files that generated within the archive directory:</p>
<ul class="simple">
<li><p>bentoml.yml: A YAML file contains all of the metadata related to this service
and archive.</p></li>
<li><p>setup.py: The configuration file that makes this BentoML service archive
‘pip’ installable</p></li>
<li><p>Dockerfile: for building Docker image that expose this Bento service as REST
API service.</p></li>
</ul>
</div>
<div class="section" id="using-bentoml-archive">
<h3>Using BentoML archive<a class="headerlink" href="#using-bentoml-archive" title="Permalink to this headline">¶</a></h3>
<p><em>For demoing purpose, copy the generated service archive into ./model folder</em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="s1">&#39;./model&#39;</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">shutil</span><span class="o">.</span><span class="n">copytree</span><span class="p">(</span><span class="n">saved_path</span><span class="p">,</span> <span class="s1">&#39;./model)</span>
</pre></div>
</div>
<div class="section" id="real-time-serving-with-rest-api">
<h4>Real-time serving with REST API<a class="headerlink" href="#real-time-serving-with-rest-api" title="Permalink to this headline">¶</a></h4>
<p>To exposing your ML service as HTTP API endpoint, you can simply use the
bentoml serve command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!bentoml serve ./model
</pre></div>
</div>
<p>With <cite>bentoml serve</cite> command, a web server will start locally at the port 5000.
We created additional endpoints that make this server ready for production.</p>
<ul class="simple">
<li><p><cite>/</cite>: The index page with swagger definition.</p></li>
<li><p><cite>/metrics</cite>: Expose system and latency metrics with Prometheus.</p></li>
<li><p><cite>/healthz</cite>: Check on your service health.</p></li>
<li><p><cite>/feedback</cite>: Add business feedback for the predicted results.</p></li>
</ul>
</div>
<div class="section" id="run-rest-api-server-with-docker">
<h4>Run REST API server with Docker<a class="headerlink" href="#run-rest-api-server-with-docker" title="Permalink to this headline">¶</a></h4>
<p>To deploy the Bento service as REST api server for production use, we can use
the generated Dockerfile to create Docker image for that.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!cd ./model &amp;&amp; docker build -t iris-classifier .
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!docker run -p 5000:5000 iris-classifier
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To generate Docker image, you will need to install Docker on your system. Please
follow direction from this link: <a class="reference external" href="https://docs.docker.com/install">https://docs.docker.com/install</a></p>
</div>
</div>
<div class="section" id="loading-bento-service-archive-in-python">
<h4>Loading Bento service archive in Python<a class="headerlink" href="#loading-bento-service-archive-in-python" title="Permalink to this headline">¶</a></h4>
<p>The easiest to use Bento service archive in your python application is using
<cite>bentoml.load</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">bentoml</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="n">bento_svc</span> <span class="o">=</span> <span class="n">bentoml</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;./model&#39;</span><span class="p">)</span>
<span class="n">bento_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="section" id="pip-install-a-bentoml-service-archive">
<h4><cite>pip install</cite> a BentoML service archive<a class="headerlink" href="#pip-install-a-bentoml-service-archive" title="Permalink to this headline">¶</a></h4>
<p>BentoML support distributing Bento service as PyPi package, with the generated
<cite>setup.py</cite> file. Bento service archive can be installed with pip:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!pip install ./model
</pre></div>
</div>
<p>Bento service archive can be uploaded to pypi.org as public python package or
to your organization’s private PyPi index for all developers in your org to
use.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> ./model <span class="p">&amp;</span> python setup.py sdist upload
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You will have to configure “.pypirc” file before uploading to pypi index.
You can find more information about distributing python package at:
<a class="reference external" href="https://docs.python.org/3.7/distributing/index.html#distributing-index">https://docs.python.org/3.7/distributing/index.html#distributing-index</a></p>
</div>
<p>After pip install, we can import the Bento service as regular python package.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IrisClassifier</span>

<span class="n">installed_svc</span> <span class="o">=</span> <span class="n">IrisClassifier</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">installed_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="section" id="cli-access-with-bentoml-service-archive">
<h4>CLI access with BentoML service archive<a class="headerlink" href="#cli-access-with-bentoml-service-archive" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!IrisClassifier info
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!IrisClassifier --help
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!IrisClassifier predict --help
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!IrisClassifier predict --input=&#39;[[5.1, 3.5, 1.4, 0.2]]&#39;
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!bentoml info ./model
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!bentoml predict ./model --input=&#39;[[5.1, 3.5, 1.4, 0.2]]&#39;
</pre></div>
</div>
</div>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">BentoML</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quick Start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#install-bentoml">Install BentoML</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-the-quick-start-project">Running the quick start project</a></li>
<li class="toctree-l2"><a class="reference internal" href="#quick-start-walk-through">Quick start walk through</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#add-bentoml-to-the-notebook-and-training-classification-model">Add BentoML to the notebook and training classification model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#define-machine-learning-service-with-bentoml">Define machine learning service with BentoML</a></li>
<li class="toctree-l3"><a class="reference internal" href="#save-defined-ml-service-as-bentoml-service-archive">Save defined ML service as BentoML service archive</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-bentoml-archive">Using BentoML archive</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#real-time-serving-with-rest-api">Real-time serving with REST API</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-rest-api-server-with-docker">Run REST API server with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="#loading-bento-service-archive-in-python">Loading Bento service archive in Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pip-install-a-bentoml-service-archive"><cite>pip install</cite> a BentoML service archive</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cli-access-with-bentoml-service-archive">CLI access with BentoML service archive</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cli.html">CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="cli.html#deployment">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/bentoml.html">API</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">BentoML Documentation</a></li>
      <li>Next: <a href="cli.html" title="next chapter">CLI</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Atalaya.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.0.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/quickstart.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>