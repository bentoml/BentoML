{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BentoML Example: Sentiment Analysis with Scikit-learn\n",
    "\n",
    "\n",
    "[BentoML](http://bentoml.ai) is an open source framework for building, shipping and running machine learning services. It provides high-level APIs for defining an ML service and packaging its artifacts, source code, dependencies, and configurations into a production-system-friendly format that is ready for deployment.\n",
    "\n",
    "This notebook demonstrates how to use BentoML to turn a scikit-learn model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
    "\n",
    "\n",
    "*The example is based on [this notebook](https://github.com/crawles/sentiment_analysis_twitter_model/blob/master/build-sentiment-classifier.ipynb), using dataset from [Sentiment140](http://help.sentiment140.com/for-students/)*\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=nb&ea=open&el=official-example&dt=sklearn-sentiment-clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bentoml\n",
    "!pip install sklearn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import bentoml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -f ./trainingandtestdata.zip ]; then\n",
    "    wget -q http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
    "    unzip -n trainingandtestdata.zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['polarity', 'tweetid', 'date', 'query_name', 'user', 'text']\n",
    "dftrain = pd.read_csv('training.1600000.processed.noemoticon.csv',\n",
    "                      header = None,\n",
    "                      encoding ='ISO-8859-1')\n",
    "dftest = pd.read_csv('testdata.manual.2009.06.14.csv',\n",
    "                     header = None,\n",
    "                     encoding ='ISO-8859-1')\n",
    "dftrain.columns = columns\n",
    "dftest.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiment_lr = Pipeline([\n",
    "                         ('count_vect', CountVectorizer(min_df = 100,\n",
    "                                                        ngram_range = (1,1),\n",
    "                                                        stop_words = 'english')), \n",
    "                         ('lr', LogisticRegression())])\n",
    "sentiment_lr.fit(dftrain.text, dftrain.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtest, ytest = dftest.text[dftest.polarity!=2], dftest.polarity[dftest.polarity!=2]\n",
    "print(classification_report(ytest,sentiment_lr.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lr.predict([Xtest[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ML Service with BentoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile sentiment_lr_model.py\n",
    "import pandas as pd\n",
    "import bentoml\n",
    "from bentoml.artifact import PickleArtifact\n",
    "from bentoml.handlers import DataframeHandler\n",
    "\n",
    "@bentoml.artifacts([PickleArtifact('sentiment_lr')])\n",
    "@bentoml.env(pip_dependencies=[\"scikit-learn\", \"pandas\"])\n",
    "class SentimentLRModel(bentoml.BentoService):\n",
    "\n",
    "    @bentoml.api(DataframeHandler, typ='series')\n",
    "    def predict(self, series):\n",
    "        \"\"\"\n",
    "        predict expects pandas.Series as input\n",
    "        \"\"\"        \n",
    "        return self.artifacts.sentiment_lr.predict(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save BentoML service archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_lr_model import SentimentLRModel\n",
    "\n",
    "# Initialize bentoML model with artifacts\n",
    "\n",
    "bento_model = SentimentLRModel.pack(\n",
    "    sentiment_lr=sentiment_lr\n",
    ")\n",
    "\n",
    "# Save bentoML model to directory\n",
    "saved_path = bento_model.save(\"/tmp/bento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BentoML Service from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "# Load exported bentoML model archive from path\n",
    "bento_model = bentoml.load(saved_path)\n",
    "\n",
    "# Call predict on the restored sklearn model\n",
    "bento_model.predict(pd.Series([\"hello\", \"hi\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"pip install\" a BentoML archive\n",
    "\n",
    "BentoML user can directly pip install saved BentoML archive with `pip install {saved_path}`,  and use it as a regular python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install {saved_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your bentoML model class name will become packaged name\n",
    "import SentimentLRModel\n",
    "\n",
    "ms = SentimentLRModel.load() # call load to ensure all artifacts are loaded\n",
    "ms.predict(pd.Series([\"stupid\", \"awesome\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI access\n",
    "\n",
    "`pip install saved_path` also installs a CLI tool for accessing the BentoML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!SentimentLRModel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!SentimentLRModel --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!SentimentLRModel predict --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction with sample input\n",
    "!SentimentLRModel predict --input='[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAPI docs for generating API Client\n",
    "!SentimentLRModel docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run REST API server locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve {saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send prediction request to REST API server\n",
    "\n",
    "*Run the following command in terminal to make a HTTP request to the API server*\n",
    "```bash\n",
    "curl -i \\\n",
    "--header \"Content-Type: application/json\" \\\n",
    "--request POST \\\n",
    "--data '[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]' \\\n",
    "localhost:5000/predict\n",
    "```\n",
    "\n",
    "You can also view all availabl API endpoints at [localhost:5000](localhost:5000), or look at prometheus metrics at [localhost:5000/metrics](localhost:5000/metrics) in browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run REST API server with Docker\n",
    "\n",
    "** _Note: `docker` is not available when running in Google Colaboratory_\n",
    "\n",
    "### 1) build docker image with saved Bento and tag it (e.g. sentiment-lr-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {saved_path} && docker build -t sentiment-lr-model ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) run docker image and expose port 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 5000:5000 sentiment-lr-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Similarly use the following command to query the REST server in Docker\n",
    "\n",
    "```bash\n",
    "curl -i \\\n",
    "--header \"Content-Type: application/json\" \\\n",
    "--request POST \\\n",
    "--data '[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]' \\\n",
    "localhost:5000/predict\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
