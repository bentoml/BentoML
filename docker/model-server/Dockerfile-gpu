# NOTE: we will handle different CUDA and CUDNN version in future release.
# For now we will use cuda11.3 with cudnn8.2.0
ARG PYTHON_VERSION
ARG CUDA=11.3
ARG CUDNN_MAJOR_VERSION=8
ARG UBUNTU_VERSION=20.04

FROM nvidia/cuda:${CUDA}.0-cudnn${CUDNN_MAJOR_VERSION}-runtime-ubuntu${UBUNTU_VERSION} as compile-base

FROM python:${PYTHON_VERSION}-slim as build-base
RUN apt-get update && apt-get install -y --no-install-recommends build-essential gcc

ARG BENTOML_VERSION=0.12.1
ENV BENTOML_VERSION=$BENTOML_VERSION

RUN python -m venv /opt/venv
# Make sure we use the virtualenv:
ENV PATH="/opt/venv/bin:$PATH"

# pre-install BentoML requirements
RUN pip install bentoml[model_server]==$BENTOML_VERSION --no-cache-dir
COPY entrypoint.sh .

# multi-stage build to shave dependency cost
FROM python:${PYTHON_VERSION}-slim AS build-image
COPY --from=build-base /opt/venv /opt/venv
COPY --from=build-base entrypoint.sh /usr/local/bin

COPY --from=compile-base /usr/local/cuda /usr/local/cuda
COPY --from=compile-base /usr/lib/x86_64-linux-gnu/libcudnn* /usr/local/cuda/lib64/


# Make sure we use the virtualenv:
ENV PATH="/opt/venv/bin:/usr/local/cuda/bin:$PATH"
ENV LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"

ENTRYPOINT [ "entrypoint.sh" ]
CMD ["bentoml", "serve-gunicorn", "/bento"]